// Amalgamated source file generated from:
// Header files:
//   - cache.h
//   - config.h
//   - mojo.h
//   - state.h
//   - timing.h
//   - vm.h
//   - render.h
//   - cpython/tasks.h
//   - interp.h
//   - long.h
//   - mirrors.h
//   - stack_chunk.h
//   - strings.h
//   - frame.h
//   - stacks.h
//   - greenlets.h
//   - signals.h
//   - tasks.h
//   - threads.h
//   - memory.h
// Source files:
//   - coremodule.cc
//   - frame.cc
//   - render.cc
//
// This file is automatically generated. Do not edit directly.

#define Py_BUILD_CORE

// TODO: Those are temporary things

#include <execinfo.h>
#include <iostream>
#include <cstdlib>

void print_backtrace() {
    void* array[64];
    int size = backtrace(array, 64);
    char** symbols = backtrace_symbols(array, size);
    std::cerr << "Backtrace:\n";
    for (int i = 0; i < size; ++i) {
        std::cerr << "  " << symbols[i] << '\n';
    }
    free(symbols);
}

// System includes
#include <Python.h>
#include <algorithm>
#include <array>
#include <condition_variable>
#include <cstdint>
#include <cstdio>
#include <cstdlib>
#include <cstring>
#include <deque>
#include <dictobject.h>
#include <exception>
#include <fcntl.h>
#include <frameobject.h>
#include <fstream>
#include <functional>
#include <iostream>
#include <list>
#include <memory>
#include <mutex>
#include <optional>
#include <ostream>
#include <sched.h>
#include <setobject.h>
#include <signal.h>
#include <stack>
#include <stdexcept>
#include <string>
#include <string_view>
#include <sys/resource.h>
#include <sys/stat.h>
#include <sys/types.h>
#include <thread>
#include <time.h>
#include <unicodeobject.h>
#include <unistd.h>
#include <unordered_map>
#include <unordered_set>
#include <vector>
#include <weakrefobject.h>

// ============================================================================
// HEADER FILES
// ============================================================================

// ============================================================================
// Header: cache.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.


void sampler();

#define CACHE_MAX_ENTRIES 2048

template <typename K, typename V>
class LRUCache
{
public:
    LRUCache(size_t capacity) : capacity(capacity) {}

    V& lookup(const K& k);

    void store(const K& k, std::unique_ptr<V> v);

    class LookupError : public std::exception
    {
    public:
        const char* what() const noexcept override
        {
            return "Key not found in cache";
        }
    };

private:
    size_t capacity;
    std::list<std::pair<K, std::unique_ptr<V>>> items;
    std::unordered_map<K, typename std::list<std::pair<K, std::unique_ptr<V>>>::iterator> index;
};

template <typename K, typename V>
void LRUCache<K, V>::store(const K& k, std::unique_ptr<V> v)
{
    // Check if cache is full
    if (items.size() >= capacity)
    {
        index.erase(items.back().first);
        items.pop_back();
    }

    // Insert the new item at front of the list
    items.emplace_front(k, std::move(v));

    // Insert in the map
    index[k] = items.begin();
}

template <typename K, typename V>
V& LRUCache<K, V>::lookup(const K& k)
{
    auto itr = index.find(k);
    if (itr == index.end())
        throw LookupError();

    // Move to the front of the list
    items.splice(items.begin(), items, itr->second);

    return *(itr->second->second.get());
}


// ============================================================================
// Header: config.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.


#define PY_SSIZE_T_CLEAN



// Sampling interval
unsigned int interval = 1000;

// CPU Time mode
int cpu = 0;

// For cpu time mode, Echion only unwinds threads that're running by default.
// Set this to false to unwind all threads.
bool ignore_non_running_threads = true;

// Memory events
int memory = 0;

// Native stack sampling
int native = 0;

// Where mode
int where = 0;

// Maximum number of frames to unwind
unsigned int max_frames = 2048;

// Pipe name (where mode IPC)
std::string pipe_name;

// ----------------------------------------------------------------------------
PyObject* set_interval(PyObject* Py_UNUSED(m), PyObject* args)
{
    unsigned int new_interval;
    if (!PyArg_ParseTuple(args, "I", &new_interval))
        return NULL;

    interval = new_interval;

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
void _set_cpu(int new_cpu)
{
    cpu = new_cpu;
}

// ----------------------------------------------------------------------------
void _set_ignore_non_running_threads(bool new_ignore_non_running_threads)
{
    ignore_non_running_threads = new_ignore_non_running_threads;
}

// ----------------------------------------------------------------------------
PyObject* set_cpu(PyObject* Py_UNUSED(m), PyObject* args)
{
    int new_cpu;
    if (!PyArg_ParseTuple(args, "p", &new_cpu))
        return NULL;

    _set_cpu(new_cpu);

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* set_memory(PyObject* Py_UNUSED(m), PyObject* args)
{
    int new_memory;
    if (!PyArg_ParseTuple(args, "p", &new_memory))
        return NULL;

    memory = new_memory;

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* set_native(PyObject* Py_UNUSED(m), PyObject* args)
{
#ifndef UNWIND_NATIVE_DISABLE
    int new_native;
    if (!PyArg_ParseTuple(args, "p", &new_native))
        return NULL;

    native = new_native;
#else
    PyErr_SetString(PyExc_RuntimeError,
                    "Native profiling is disabled, please re-build/install echion without "
                    "UNWIND_NATIVE_DISABLE env var/preprocessor flag");
    return NULL;
#endif  // UNWIND_NATIVE_DISABLE
    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* set_where(PyObject* Py_UNUSED(m), PyObject* args)
{
    int value;
    if (!PyArg_ParseTuple(args, "p", &value))
        return NULL;

    where = value;

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* set_pipe_name(PyObject* Py_UNUSED(m), PyObject* args)
{
    const char* name;
    if (!PyArg_ParseTuple(args, "s", &name))
        return NULL;

    pipe_name = name;

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* set_max_frames(PyObject* Py_UNUSED(m), PyObject* args)
{
    unsigned int new_max_frames;
    if (!PyArg_ParseTuple(args, "I", &new_max_frames))
        return NULL;

    max_frames = new_max_frames;

    Py_RETURN_NONE;
}


// ============================================================================
// Header: mojo.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.


#define MOJO_VERSION 3

enum MojoEvent
{
    MOJO_RESERVED,
    MOJO_METADATA,
    MOJO_STACK,
    MOJO_FRAME,
    MOJO_FRAME_INVALID,
    MOJO_FRAME_REF,
    MOJO_FRAME_KERNEL,
    MOJO_GC,
    MOJO_IDLE,
    MOJO_METRIC_TIME,
    MOJO_METRIC_MEMORY,
    MOJO_STRING,
    MOJO_STRING_REF,
    MOJO_MAX,
};

#if defined __arm__
using mojo_int_t = long;
using mojo_uint_t = unsigned long;
using mojo_ref_t = unsigned long;
#else
using mojo_int_t = long long;
using mojo_uint_t = unsigned long long;
using mojo_ref_t = unsigned long long;
#endif


// ============================================================================
// Header: state.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.


#define PY_SSIZE_T_CLEAN
#if defined __GNUC__ && defined HAVE_STD_ATOMIC
#undef HAVE_STD_ATOMIC
#endif
#define Py_BUILD_CORE

#define PY_SSIZE_T_CLEAN
#include <Python.h>
#if defined __GNUC__ && defined HAVE_STD_ATOMIC
#undef HAVE_STD_ATOMIC
#endif
#define Py_BUILD_CORE
#include <internal/pycore_pystate.h>

_PyRuntimeState* runtime = &_PyRuntime;
PyThreadState* current_tstate = NULL;

std::thread* sampler_thread = nullptr;

int running = 0;

std::thread* where_thread = nullptr;
std::condition_variable where_cv;
std::mutex where_lock;

PyObject* asyncio_current_tasks = NULL;
PyObject* asyncio_scheduled_tasks = NULL;  // WeakSet
PyObject* asyncio_eager_tasks = NULL;      // set


// ============================================================================
// Header: timing.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.


#if defined PL_LINUX
#include <time.h>
#elif defined PL_DARWIN
#include <mach/clock.h>
#include <mach/mach.h>

clock_serv_t cclock;
#endif

typedef unsigned long microsecond_t;

microsecond_t last_time = 0;

#define TS_TO_MICROSECOND(ts) ((ts).tv_sec * 1e6 + (ts).tv_nsec / 1e3)
#define TV_TO_MICROSECOND(tv) ((tv).seconds * 1e6 + (tv).microseconds)

// ----------------------------------------------------------------------------
microsecond_t gettime()
{
#if defined PL_LINUX
    struct timespec ts;
    if (clock_gettime(CLOCK_BOOTTIME, &ts))
        return 0;
    return TS_TO_MICROSECOND(ts);
#elif defined PL_DARWIN
    mach_timespec_t ts;
    clock_get_time(cclock, &ts);
    return TS_TO_MICROSECOND(ts);
#endif
}


// ============================================================================
// Header: vm.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.



#if defined PL_LINUX
#include <fcntl.h>
#include <sys/mman.h>
#include <sys/stat.h>
#include <sys/types.h>
#include <sys/uio.h>
#include <unistd.h>
#include <algorithm>

typedef pid_t proc_ref_t;

ssize_t process_vm_readv(pid_t, const struct iovec*, unsigned long liovcnt,
                         const struct iovec* remote_iov, unsigned long riovcnt,
                         unsigned long flags);

#define copy_type(addr, dest) (copy_memory(pid, addr, sizeof(dest), &dest))
#define copy_type_p(addr, dest) (copy_memory(pid, addr, sizeof(*dest), dest))
#define copy_generic(addr, dest, size) (copy_memory(pid, (void*)(addr), size, (void*)(dest)))

#elif defined PL_DARWIN
#include <mach/mach.h>
#include <mach/mach_vm.h>
#include <mach/machine/kern_return.h>
#include <sys/sysctl.h>
#include <sys/types.h>

typedef mach_port_t proc_ref_t;

#define copy_type(addr, dest) (copy_memory(mach_task_self(), addr, sizeof(dest), &dest))
#define copy_type_p(addr, dest) (copy_memory(mach_task_self(), addr, sizeof(*dest), dest))
#define copy_generic(addr, dest, size) \
    (copy_memory(mach_task_self(), (void*)(addr), size, (void*)(dest)))
#endif

// Some checks are done at static initialization, so use this to read them at runtime
bool failed_safe_copy = false;

#if defined PL_LINUX
ssize_t (*safe_copy)(pid_t, const struct iovec*, unsigned long, const struct iovec*,
                            unsigned long, unsigned long) = process_vm_readv;

class VmReader
{
    void* buffer{nullptr};
    size_t sz{0};
    int fd{-1};
    inline static VmReader* instance{nullptr};  // Prevents having to set this in implementation

    void* init(size_t new_sz)
    {
        // Makes a temporary file and ftruncates it to the specified size
        std::array<std::string, 3> tmp_dirs = {"/dev/shm", "/tmp", "/var/tmp"};
        std::string tmp_suffix = "/echion-XXXXXX";
        void* ret = nullptr;

        for (auto& tmp_dir : tmp_dirs)
        {
            // Reset the file descriptor, just in case
            close(fd);
            fd = -1;

            // Create the temporary file
            std::string tmpfile = tmp_dir + tmp_suffix;
            fd = mkstemp(tmpfile.data());
            if (fd == -1)
                continue;

            // Unlink might fail if delete is blocked on the VFS, but currently no action is taken
            unlink(tmpfile.data());

            // Make sure we have enough size
            if (ftruncate(fd, new_sz) == -1)
            {
                continue;
            }

            // Map the file
            ret = mmap(NULL, new_sz, PROT_READ | PROT_WRITE, MAP_PRIVATE, fd, 0);
            if (ret == MAP_FAILED)
            {
                ret = nullptr;
                continue;
            }

            // Successful.  Break.
            sz = new_sz;
            break;
        }

        return ret;
    }

    VmReader(size_t _sz) : sz{_sz}
    {
        buffer = init(sz);
        if (!buffer)
        {
            throw std::runtime_error("Failed to initialize buffer with size " + std::to_string(sz));
        }
        instance = this;
    }

public:
    static VmReader* get_instance()
    {
        if (instance == nullptr)
        {
            try
            {
                instance = new VmReader(1024 * 1024);  // A megabyte?
            }
            catch (std::exception& e)
            {
                std::cerr << "Failed to initialize VmReader: " << e.what() << std::endl;
            }
        }
        return instance;
    }

    ssize_t safe_copy(pid_t pid, const struct iovec* local_iov, unsigned long liovcnt,
                      const struct iovec* remote_iov, unsigned long riovcnt, unsigned long flags)
    {
        (void)pid;
        (void)flags;
        if (liovcnt != 1 || riovcnt != 1)
        {
            // Unsupported
            return 0;
        }

        // Check to see if we need to resize the buffer
        if (remote_iov[0].iov_len > sz)
        {
            if (ftruncate(fd, remote_iov[0].iov_len) == -1)
            {
                return 0;
            }
            else
            {
                void* tmp = mremap(buffer, sz, remote_iov[0].iov_len, MREMAP_MAYMOVE);
                if (tmp == MAP_FAILED)
                {
                    return 0;
                }
                buffer = tmp;  // no need to munmap
                sz = remote_iov[0].iov_len;
            }
        }

        ssize_t ret = pwritev(fd, remote_iov, riovcnt, 0);
        if (ret == -1)
        {
            return ret;
        }

        // Copy the data from the buffer to the remote process
        std::memcpy(local_iov[0].iov_base, buffer, local_iov[0].iov_len);
        return ret;
    }

    ~VmReader()
    {
        if (buffer)
        {
            munmap(buffer, sz);
        }
        if (fd != -1)
        {
            close(fd);
        }
        instance = nullptr;
    }
};

/**
 * Initialize the safe copy operation on Linux
 */
bool read_process_vm_init()
{
    VmReader* _ = VmReader::get_instance();
    return !!_;
}

ssize_t vmreader_safe_copy(pid_t pid, const struct iovec* local_iov, unsigned long liovcnt,
                                  const struct iovec* remote_iov, unsigned long riovcnt,
                                  unsigned long flags)
{
    auto reader = VmReader::get_instance();
    if (!reader)
        return 0;
    return reader->safe_copy(pid, local_iov, liovcnt, remote_iov, riovcnt, flags);
}

/**
 * Initialize the safe copy operation on Linux
 *
 * This occurs at static init
 */
__attribute__((constructor)) inline void init_safe_copy()
{
    char src[128];
    char dst[128];
    for (size_t i = 0; i < 128; i++)
    {
        src[i] = 0x41;
        dst[i] = ~0x42;
    }

    // Check to see that process_vm_readv works, unless it's overridden
    const char force_override_str[] = "ECHION_ALT_VM_READ_FORCE";
    const std::array<std::string, 6> truthy_values = {"1",  "true",   "yes",
                                                      "on", "enable", "enabled"};
    const char* force_override = std::getenv(force_override_str);
    if (!force_override || std::find(truthy_values.begin(), truthy_values.end(), force_override) ==
                               truthy_values.end())
    {
        struct iovec iov_dst = {dst, sizeof(dst)};
        struct iovec iov_src = {src, sizeof(src)};
        ssize_t result = process_vm_readv(getpid(), &iov_dst, 1, &iov_src, 1, 0);

        // If we succeed, then use process_vm_readv
        if (result == sizeof(src))
        {
            safe_copy = process_vm_readv;
            return;
        }
    }

    // Else, we have to setup the writev method
    if (!read_process_vm_init())
    {
        // std::cerr might not have been fully initialized at this point, so use
        // fprintf instead.
        fprintf(stderr, "Failed to initialize all safe copy interfaces\n");
        failed_safe_copy = true;
        return;
    }

    safe_copy = vmreader_safe_copy;
}
#endif

/**
 * Copy a chunk of memory from a portion of the virtual memory of another
 * process.
 * @param proc_ref_t  the process reference (platform-dependent)
 * @param void *      the remote address
 * @param ssize_t     the number of bytes to read
 * @param void *      the destination buffer, expected to be at least as large
 *                    as the number of bytes to read.
 *
 * @return  zero on success, otherwise non-zero.
 */
int copy_memory(proc_ref_t proc_ref, void* addr, ssize_t len, void* buf)
{
    ssize_t result = -1;

    // Early exit on zero page
    if (reinterpret_cast<uintptr_t>(addr) < 4096)
    {
        return result;
    }

#if defined PL_LINUX
    struct iovec local[1];
    struct iovec remote[1];

    local[0].iov_base = buf;
    local[0].iov_len = len;
    remote[0].iov_base = addr;
    remote[0].iov_len = len;

    result = safe_copy(proc_ref, local, 1, remote, 1, 0);

#elif defined PL_DARWIN
    kern_return_t kr = mach_vm_read_overwrite(proc_ref, (mach_vm_address_t)addr, len,
                                              (mach_vm_address_t)buf, (mach_vm_size_t*)&result);

    if (kr != KERN_SUCCESS)
        return -1;

#endif

    return len != result;
}

pid_t pid = 0;

void _set_pid(pid_t _pid)
{
    pid = _pid;
}


// ============================================================================
// Header: render.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.




// Forward declaration
class Frame;

enum MetricType
{
    Time,
    Memory
};

class RendererInterface
{
public:
    virtual void open() = 0;
    virtual void close() = 0;
    virtual void header() = 0;
    virtual void metadata(const std::string& label, const std::string& value) = 0;
    // If a renderer has its own caching mechanism for frames, this can be used
    // to store frame information.
    virtual void frame(mojo_ref_t key, mojo_ref_t filename, mojo_ref_t name, mojo_int_t line,
                       mojo_int_t line_end, mojo_int_t column, mojo_int_t column_end) = 0;
    // Refers to the frame stored using above function
    virtual void frame_ref(mojo_ref_t key) = 0;
    virtual void frame_kernel(const std::string& scope) = 0;
    // Simlar to frame/frame_ref functions, helpers for string tables
    virtual void string(mojo_ref_t key, const std::string& value) = 0;
    virtual void string_ref(mojo_ref_t key) = 0;

    virtual void render_message(std::string_view msg) = 0;
    virtual void render_thread_begin(PyThreadState* tstate, std::string_view name,
                                     microsecond_t cpu_time, uintptr_t thread_id,
                                     unsigned long native_id) = 0;
    virtual void render_task_begin(std::string task_name, bool on_cpu) = 0;
    virtual void render_stack_begin(long long pid, long long iid,
                                    const std::string& thread_name) = 0;
    virtual void render_frame(Frame& frame) = 0;
    virtual void render_cpu_time(uint64_t cpu_time) = 0;
    virtual void render_stack_end(MetricType metric_type, uint64_t delta) = 0;

    // The validity of the interface is a two-step process
    // 1. If the RendererInterface has been destroyed, obviously it's invalid
    // 2. There might be state behind RendererInterface, and the lifetime of that
    //    state alone may be insufficient to know its usability.  is_valid
    //    should return false in such cases.
    virtual bool is_valid() = 0;
    virtual ~RendererInterface() = default;
};

class WhereRenderer : public RendererInterface
{
private:
    std::ostream* output;
    std::ofstream file_stream;

    WhereRenderer() {}
    ~WhereRenderer() {}

public:
    static WhereRenderer& get()
    {
        static WhereRenderer instance;
        return instance;
    }

    WhereRenderer(WhereRenderer&) = delete;
    WhereRenderer(WhereRenderer&&) = delete;
    void operator=(const WhereRenderer&) = delete;

    bool set_output(std::string_view file_name)
    {
        file_stream.close();
        file_stream.open(file_name.data(), std::ios::out);
        if (file_stream.is_open())
        {
            output = &file_stream;
            return true;
        }
        return false;
    }

    bool set_output(std::ostream& new_output)
    {
        file_stream.close();
        output = &new_output;
        return true;
    }

    void open() override {};
    void close() override {};
    void header() override {};
    void metadata(const std::string& label, const std::string& value) override {};
    void frame(mojo_ref_t key, mojo_ref_t filename, mojo_ref_t name, mojo_int_t line,
               mojo_int_t line_end, mojo_int_t column, mojo_int_t column_end) override {};
    void frame_ref(mojo_ref_t key) override {};
    void frame_kernel(const std::string& scope) override {};
    void string(mojo_ref_t key, const std::string& value) override {};
    void string_ref(mojo_ref_t key) override {};

    void render_thread_begin(PyThreadState*, std::string_view name, microsecond_t, uintptr_t,
                             unsigned long) override
    {
        *output << "    ðŸ§µ " << name << ":" << std::endl;
    }
    void render_task_begin(std::string task_name, bool on_cpu) override {}
    void render_stack_begin(long long, long long, const std::string&) override {}
    void render_message(std::string_view msg) override
    {
        *output << msg << std::endl;
    }
    void render_frame(Frame&) override;
    void render_stack_end(MetricType, uint64_t) override {}
    void render_cpu_time(uint64_t) override {}

    bool is_valid() override
    {
        return true;
    }
};

class MojoRenderer : public RendererInterface
{
    std::ofstream output;
    std::mutex lock;
    uint64_t metric = 0;

    void inline event(MojoEvent event)
    {
        output.put((char)event);
    }
    void inline string(const std::string& string)
    {
        output << string << '\0';
    }
    void inline string(const char* string)
    {
        output << string << '\0';
    }
    void inline ref(mojo_ref_t value)
    {
        integer(value);
    }
    void inline integer(mojo_int_t n)
    {
        mojo_uint_t integer = n < 0 ? -n : n;
        bool sign = n < 0;

        unsigned char byte = integer & 0x3f;
        if (sign)
            byte |= 0x40;

        integer >>= 6;
        if (integer)
            byte |= 0x80;

        output.put(byte);

        while (integer)
        {
            byte = integer & 0x7f;
            integer >>= 7;
            if (integer)
                byte |= 0x80;
            output.put(byte);
        }
    }

public:
    MojoRenderer() = default;

    void open() override
    {
        output.open(std::getenv("ECHION_OUTPUT"));
        if (!output.is_open())
        {
            std::cerr << "Failed to open output file " << std::getenv("ECHION_OUTPUT") << std::endl;
            throw std::runtime_error("Failed to open output file");
        }
    }

    // ------------------------------------------------------------------------
    void close() override
    {
        std::lock_guard<std::mutex> guard(lock);

        output.flush();
        output.close();
    }

    // ------------------------------------------------------------------------
    void inline header() override
    {
        std::lock_guard<std::mutex> guard(lock);

        output << "MOJ";
        integer(MOJO_VERSION);
    }

    // ------------------------------------------------------------------------
    void inline metadata(const std::string& label, const std::string& value) override
    {
        std::lock_guard<std::mutex> guard(lock);

        event(MOJO_METADATA);
        string(label);
        string(value);
    }

    // ------------------------------------------------------------------------
    void inline stack(mojo_int_t pid, mojo_int_t iid, const std::string& thread_name)
    {
        std::lock_guard<std::mutex> guard(lock);

        event(MOJO_STACK);
        integer(pid);
        integer(iid);
        string(thread_name);
    }

    // ------------------------------------------------------------------------
    void inline frame(mojo_ref_t key, mojo_ref_t filename, mojo_ref_t name, mojo_int_t line,
                      mojo_int_t line_end, mojo_int_t column, mojo_int_t column_end) override
    {
        std::lock_guard<std::mutex> guard(lock);

        event(MOJO_FRAME);
        ref(key);
        ref(filename);
        ref(name);
        integer(line);
        integer(line_end);
        integer(column);
        integer(column_end);
    }

    // ------------------------------------------------------------------------
    void inline frame_ref(mojo_ref_t key) override
    {
        std::lock_guard<std::mutex> guard(lock);

        if (key == 0)
        {
            event(MOJO_FRAME_INVALID);
        }
        else
        {
            event(MOJO_FRAME_REF);
            ref(key);
        }
    }

    // ------------------------------------------------------------------------
    void inline frame_kernel(const std::string& scope) override
    {
        std::lock_guard<std::mutex> guard(lock);

        event(MOJO_FRAME_KERNEL);
        string(scope);
    }

    // ------------------------------------------------------------------------
    void inline metric_time(mojo_int_t value)
    {
        std::lock_guard<std::mutex> guard(lock);

        event(MOJO_METRIC_TIME);
        integer(value);
    }

    // ------------------------------------------------------------------------
    void inline metric_memory(mojo_int_t value)
    {
        std::lock_guard<std::mutex> guard(lock);

        event(MOJO_METRIC_MEMORY);
        integer(value);
    }

    // ------------------------------------------------------------------------
    void inline string(mojo_ref_t key, const std::string& value) override
    {
        std::lock_guard<std::mutex> guard(lock);

        event(MOJO_STRING);
        ref(key);
        string(value);
    }

    // ------------------------------------------------------------------------
    void inline string_ref(mojo_ref_t key) override
    {
        std::lock_guard<std::mutex> guard(lock);

        event(MOJO_STRING_REF);
        ref(key);
    }

    void render_message(std::string_view msg) override {};
    void render_thread_begin(PyThreadState* tstate, std::string_view name, microsecond_t cpu_time,
                             uintptr_t thread_id, unsigned long native_id) override {};
    void render_task_begin(std::string task_name, bool on_cpu) override {};
    void render_stack_begin(long long pid, long long iid, const std::string& name) override
    {
        stack(pid, iid, name);
    };
    void render_frame(Frame& frame) override;
    void render_cpu_time(uint64_t cpu_time) override
    {
        metric = cpu_time;
    };
    void render_stack_end(MetricType metric_type, uint64_t delta) override
    {
        if (metric_type == MetricType::Time)
        {
            metric_time(cpu ? metric : delta);
        }
        else if (metric_type == MetricType::Memory)
        {
            metric_memory(delta);
        }
    };
    bool is_valid() override
    {
        return true;
    }
};

class Renderer
{
private:
    std::shared_ptr<RendererInterface> default_renderer = std::make_shared<MojoRenderer>();
    std::weak_ptr<RendererInterface> currentRenderer;

    std::shared_ptr<RendererInterface> getActiveRenderer()
    {
        if (auto renderer = currentRenderer.lock())
        {
            if (renderer->is_valid())
            {
                return renderer;
            }
        }
        return default_renderer;
    }

    Renderer() = default;
    ~Renderer() = default;

public:
    Renderer(const Renderer&) = delete;
    Renderer& operator=(const Renderer&) = delete;

    static Renderer& get()
    {
        static Renderer instance;
        return instance;
    }

    void set_renderer(std::shared_ptr<RendererInterface> renderer)
    {
        currentRenderer = renderer;
    }

    void header()
    {
        getActiveRenderer()->header();
    }

    void metadata(const std::string& label, const std::string& value)
    {
        getActiveRenderer()->metadata(label, value);
    }

    void string(mojo_ref_t key, const std::string& value)
    {
        getActiveRenderer()->string(key, value);
    }

    void frame(mojo_ref_t key, mojo_ref_t filename, mojo_ref_t name, mojo_int_t line,
               mojo_int_t line_end, mojo_int_t column, mojo_int_t column_end)
    {
        getActiveRenderer()->frame(key, filename, name, line, line_end, column, column_end);
    }

    void frame_ref(mojo_ref_t key)
    {
        getActiveRenderer()->frame_ref(key);
    }

    void frame_kernel(const std::string& scope)
    {
        getActiveRenderer()->frame_kernel(scope);
    }

    void string(mojo_ref_t key, const char* value)
    {
        getActiveRenderer()->string(key, value);
    }

    void string_ref(mojo_ref_t key)
    {
        getActiveRenderer()->string_ref(key);
    }

    void render_message(std::string_view msg)
    {
        getActiveRenderer()->render_message(msg);
    }

    void open()
    {
        getActiveRenderer()->open();
    }

    void close()
    {
        getActiveRenderer()->close();
    }

    void render_thread_begin(PyThreadState* tstate, std::string_view name, microsecond_t cpu_time,
                             uintptr_t thread_id, unsigned long native_id)
    {
        getActiveRenderer()->render_thread_begin(tstate, name, cpu_time, thread_id, native_id);
    }

    void render_task_begin(std::string task_name, bool on_cpu)
    {
        getActiveRenderer()->render_task_begin(task_name, on_cpu);
    }

    void render_stack_begin(long long pid, long long iid, const std::string& thread_name)
    {
        getActiveRenderer()->render_stack_begin(pid, iid, thread_name);
    }

    void render_frame(Frame& frame)
    {
        getActiveRenderer()->render_frame(frame);
    }

    void render_cpu_time(uint64_t cpu_time)
    {
        getActiveRenderer()->render_cpu_time(cpu_time);
    }

    void render_stack_end(MetricType metric_type, uint64_t delta)
    {
        getActiveRenderer()->render_stack_end(metric_type, delta);
    }
};


// ============================================================================
// Header: cpython/tasks.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.


#define PY_SSIZE_T_CLEAN

#if PY_VERSION_HEX >= 0x030b0000
#include <cpython/genobject.h>

#define Py_BUILD_CORE
#if PY_VERSION_HEX >= 0x030d0000
#include <opcode.h>
#else
#include <internal/pycore_opcode.h>
#include <internal/pycore_frame.h>
#endif  // PY_VERSION_HEX >= 0x030d0000
#else
#include <genobject.h>
#include <opcode.h>
#endif



extern "C" {

typedef enum
{
    STATE_PENDING,
    STATE_CANCELLED,
    STATE_FINISHED
} fut_state;

#if PY_VERSION_HEX >= 0x030d0000
#define FutureObj_HEAD(prefix)                                  \
    PyObject_HEAD PyObject* prefix##_loop;                      \
    PyObject* prefix##_callback0;                               \
    PyObject* prefix##_context0;                                \
    PyObject* prefix##_callbacks;                               \
    PyObject* prefix##_exception;                               \
    PyObject* prefix##_exception_tb;                            \
    PyObject* prefix##_result;                                  \
    PyObject* prefix##_source_tb;                               \
    PyObject* prefix##_cancel_msg;                              \
    PyObject* prefix##_cancelled_exc;                           \
    fut_state prefix##_state;                                   \
    /* These bitfields need to be at the end of the struct      \
       so that these and bitfields from TaskObj are contiguous. \
    */                                                          \
    unsigned prefix##_log_tb : 1;                               \
    unsigned prefix##_blocking : 1;

#elif PY_VERSION_HEX >= 0x030b0000
#define FutureObj_HEAD(prefix)             \
    PyObject_HEAD PyObject* prefix##_loop; \
    PyObject* prefix##_callback0;          \
    PyObject* prefix##_context0;           \
    PyObject* prefix##_callbacks;          \
    PyObject* prefix##_exception;          \
    PyObject* prefix##_exception_tb;       \
    PyObject* prefix##_result;             \
    PyObject* prefix##_source_tb;          \
    PyObject* prefix##_cancel_msg;         \
    fut_state prefix##_state;              \
    int prefix##_log_tb;                   \
    int prefix##_blocking;                 \
    PyObject* dict;                        \
    PyObject* prefix##_weakreflist;        \
    PyObject* prefix##_cancelled_exc;

#elif PY_VERSION_HEX >= 0x030a0000
#define FutureObj_HEAD(prefix)             \
    PyObject_HEAD PyObject* prefix##_loop; \
    PyObject* prefix##_callback0;          \
    PyObject* prefix##_context0;           \
    PyObject* prefix##_callbacks;          \
    PyObject* prefix##_exception;          \
    PyObject* prefix##_exception_tb;       \
    PyObject* prefix##_result;             \
    PyObject* prefix##_source_tb;          \
    PyObject* prefix##_cancel_msg;         \
    fut_state prefix##_state;              \
    int prefix##_log_tb;                   \
    int prefix##_blocking;                 \
    PyObject* dict;                        \
    PyObject* prefix##_weakreflist;        \
    _PyErr_StackItem prefix##_cancelled_exc_state;

#elif PY_VERSION_HEX >= 0x03090000
#define FutureObj_HEAD(prefix)             \
    PyObject_HEAD PyObject* prefix##_loop; \
    PyObject* prefix##_callback0;          \
    PyObject* prefix##_context0;           \
    PyObject* prefix##_callbacks;          \
    PyObject* prefix##_exception;          \
    PyObject* prefix##_result;             \
    PyObject* prefix##_source_tb;          \
    PyObject* prefix##_cancel_msg;         \
    fut_state prefix##_state;              \
    int prefix##_log_tb;                   \
    int prefix##_blocking;                 \
    PyObject* dict;                        \
    PyObject* prefix##_weakreflist;        \
    _PyErr_StackItem prefix##_cancelled_exc_state;

#else
#define FutureObj_HEAD(prefix)             \
    PyObject_HEAD PyObject* prefix##_loop; \
    PyObject* prefix##_callback0;          \
    PyObject* prefix##_context0;           \
    PyObject* prefix##_callbacks;          \
    PyObject* prefix##_exception;          \
    PyObject* prefix##_result;             \
    PyObject* prefix##_source_tb;          \
    fut_state prefix##_state;              \
    int prefix##_log_tb;                   \
    int prefix##_blocking;                 \
    PyObject* dict;                        \
    PyObject* prefix##_weakreflist;
#endif

typedef struct
{
    FutureObj_HEAD(fut)
} FutureObj;

#if PY_VERSION_HEX >= 0x030d0000
typedef struct
{
    FutureObj_HEAD(task);
    unsigned task_must_cancel : 1;
    unsigned task_log_destroy_pending : 1;
    int task_num_cancels_requested;
    PyObject* task_fut_waiter;
    PyObject* task_coro;
    PyObject* task_name;
    PyObject* task_context;
} TaskObj;

#elif PY_VERSION_HEX >= 0x030a0000
typedef struct
{
    FutureObj_HEAD(task) PyObject* task_fut_waiter;
    PyObject* task_coro;
    PyObject* task_name;
    PyObject* task_context;
    int task_must_cancel;
    int task_log_destroy_pending;
    int task_num_cancels_requested;
} TaskObj;

#else
typedef struct
{
    FutureObj_HEAD(task) PyObject* task_fut_waiter;
    PyObject* task_coro;
    PyObject* task_name;
    PyObject* task_context;
    int task_must_cancel;
    int task_log_destroy_pending;
} TaskObj;
#endif

// ---- cr_await ----

#if PY_VERSION_HEX >= 0x030c0000
#define RESUME_QUICK INSTRUMENTED_RESUME
#endif

#if PY_VERSION_HEX >= 0x030b0000
PyObject* PyGen_yf(PyGenObject* gen, PyObject* frame_addr)
{
    PyObject* yf = NULL;

    if (gen->gi_frame_state < FRAME_CLEARED)
    {
        if (gen->gi_frame_state == FRAME_CREATED)
            return NULL;

        _PyInterpreterFrame frame;
        if (copy_type(frame_addr, frame))
            return NULL;

        _Py_CODEUNIT next;
#if PY_VERSION_HEX >= 0x030d0000
        if (copy_type(frame.instr_ptr, next))
#else
        if (copy_type(frame.prev_instr + 1, next))
#endif
            return NULL;
        if (!(_Py_OPCODE(next) == RESUME || _Py_OPCODE(next) == RESUME_QUICK) ||
            _Py_OPARG(next) < 2)
            return NULL;

        if (frame.stacktop < 1 || frame.stacktop > (1 << 20))
            return NULL;

        auto localsplus = std::make_unique<PyObject*[]>(frame.stacktop);
        if (copy_generic(frame.localsplus, localsplus.get(), frame.stacktop * sizeof(PyObject*)))
            return NULL;

        yf = localsplus[frame.stacktop - 1];
    }

    return yf;
}

#elif PY_VERSION_HEX >= 0x030a0000
PyObject* PyGen_yf(PyGenObject* Py_UNUSED(gen), PyObject* frame_addr)
{
    PyObject* yf = NULL;
    PyFrameObject* f = (PyFrameObject*)frame_addr;

    if (f)
    {
        PyFrameObject frame;
        if (copy_type(f, frame))
            return NULL;

        if (frame.f_lasti < 0)
            return NULL;

        PyCodeObject code;
        if (copy_type(frame.f_code, code))
            return NULL;

        Py_ssize_t s = 0;
        auto c = pybytes_to_bytes_and_size(code.co_code, &s);
        if (c == nullptr)
            return NULL;

        if (c[(frame.f_lasti + 1) * sizeof(_Py_CODEUNIT)] != YIELD_FROM)
            return NULL;

        ssize_t nvalues = frame.f_stackdepth;
        if (nvalues < 1 || nvalues > (1 << 20))
            return NULL;

        auto stack = std::make_unique<PyObject*[]>(nvalues);

        if (copy_generic(frame.f_valuestack, stack.get(), nvalues * sizeof(PyObject*)))
            return NULL;

        yf = stack[nvalues - 1];
    }

    return yf;
}

#else
PyObject* PyGen_yf(PyGenObject* Py_UNUSED(gen), PyObject* frame_addr)
{
    PyObject* yf = NULL;
    PyFrameObject* f = (PyFrameObject*)frame_addr;

    if (frame_addr == NULL)
        return NULL;

    PyFrameObject frame;
    if (copy_type(f, frame))
        return NULL;

    if (frame.f_stacktop)
    {
        if (frame.f_lasti < 0)
            return NULL;

        PyCodeObject code;
        if (copy_type(frame.f_code, code))
            return NULL;

        Py_ssize_t s = 0;
        auto c = pybytes_to_bytes_and_size(code.co_code, &s);
        if (c == nullptr)
            return NULL;

        if (c[f->f_lasti + sizeof(_Py_CODEUNIT)] != YIELD_FROM)
            return NULL;

        auto stacktop = std::make_unique<PyObject*>();
        if (copy_generic(frame.f_stacktop - 1, stacktop.get(), sizeof(PyObject*)))
            return NULL;

        yf = *stacktop;
    }

    return yf;
}
#endif
}


// ============================================================================
// Header: interp.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.


#define PY_SSIZE_T_CLEAN

#if PY_VERSION_HEX >= 0x03090000
#define Py_BUILD_CORE
#if defined __GNUC__ && defined HAVE_STD_ATOMIC
#undef HAVE_STD_ATOMIC
#endif
#include <internal/pycore_interp.h>
#endif




class InterpreterInfo
{
public:
    int64_t id = 0;
    void* tstate_head = NULL;
    void* next = NULL;
};

void for_each_interp(std::function<void(InterpreterInfo& interp)> callback)
{
    InterpreterInfo interpreter_info = {0};

    for (char* interp_addr = (char*)runtime->interpreters.head; interp_addr != NULL;
         interp_addr = (char*)interpreter_info.next)
    {
        if (copy_type(interp_addr + offsetof(PyInterpreterState, id), interpreter_info.id))
            continue;
#if PY_VERSION_HEX >= 0x030b0000
        if (copy_type(interp_addr + offsetof(PyInterpreterState, threads.head),
#else
        if (copy_type(interp_addr + offsetof(PyInterpreterState, tstate_head),
#endif
                      interpreter_info.tstate_head))
            continue;
        if (copy_type(interp_addr + offsetof(PyInterpreterState, next), interpreter_info.next))
            continue;

        callback(interpreter_info);
    };
}


// ============================================================================
// Header: long.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.

#if PY_VERSION_HEX >= 0x030c0000
#include <internal/pycore_long.h>
// Note: Even if use the right PYLONG_BITS_IN_DIGIT that is specified in the
// Python we use to build echion, it can be different from the Python that is
// used to run the program.
#if PYLONG_BITS_IN_DIGIT == 30
typedef uint32_t digit;
#elif PYLONG_BITS_IN_DIGIT == 15
typedef unsigned short digit;
#else
#error "Unsupported PYLONG_BITS_IN_DIGIT"
#endif  // PYLONG_BITS_IN_DIGIT
#endif  // PY_VERSION_HEX >= 0x030c0000



class LongError : public std::exception
{
    const char* what() const noexcept override
    {
        return "LongError";
    }
};

// ----------------------------------------------------------------------------
#if PY_VERSION_HEX >= 0x030c0000
long long pylong_to_llong(PyObject* long_addr)
{
    // Only used to extract a task-id on Python 3.12, omits overflow checks
    PyLongObject long_obj;
    long long ret = 0;

    if (copy_type(long_addr, long_obj))
        throw LongError();

    if (!PyLong_CheckExact(&long_obj))
        throw LongError();

    if (_PyLong_IsCompact(&long_obj))
    {
        ret = (long long)_PyLong_CompactValue(&long_obj);
    }
    else
    {
        // If we're here, then we need to iterate over the digits
        // We might overflow, but we don't care for now
        int sign = _PyLong_NonCompactSign(&long_obj);
        Py_ssize_t i = _PyLong_DigitCount(&long_obj);
        // Copy over the digits as ob_digit is allocated dynamically with
        // PyObject_Malloc.
        std::vector<digit> digits(i);
        if (copy_generic(long_obj.long_value.ob_digit, digits.data(), i * sizeof(digit)))
        {
            throw LongError();
        }
        while (--i >= 0)
        {
            ret <<= PyLong_SHIFT;
            ret |= digits[i];
        }
        ret *= sign;
    }

    return ret;
}
#endif


// ============================================================================
// Header: mirrors.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.


#define PY_SSIZE_T_CLEAN

#if PY_VERSION_HEX >= 0x030b0000
#define Py_BUILD_CORE
#if defined __GNUC__ && defined HAVE_STD_ATOMIC
#undef HAVE_STD_ATOMIC
#endif
#include <internal/pycore_dict.h>
#else
typedef struct
{
    Py_hash_t me_hash;
    PyObject* me_key;
    PyObject* me_value; /* This field is only meaningful for combined tables */
} PyDictKeyEntry;

typedef Py_ssize_t (*dict_lookup_func)(PyDictObject* mp, PyObject* key, Py_hash_t hash,
                                       PyObject** value_addr);

/* See dictobject.c for actual layout of DictKeysObject */
typedef struct _dictkeysobject
{
    Py_ssize_t dk_refcnt;

    /* Size of the hash table (dk_indices). It must be a power of 2. */
    Py_ssize_t dk_size;

    dict_lookup_func dk_lookup;

    /* Number of usable entries in dk_entries. */
    Py_ssize_t dk_usable;

    /* Number of used entries in dk_entries. */
    Py_ssize_t dk_nentries;

    char dk_indices[]; /* char is required to avoid strict aliasing. */

} PyDictKeysObject;

typedef PyObject* PyDictValues;
#endif



class MirrorError : public std::exception
{
public:
    const char* what() const noexcept override
    {
        return "Cannot create mirror object";
    }
};

class MirrorObject
{
public:
    inline PyObject* reflect()
    {
        if (reflected == NULL)
            throw MirrorError();
        return reflected;
    }

protected:
    std::unique_ptr<char[]> data = nullptr;
    PyObject* reflected = NULL;
};

// ----------------------------------------------------------------------------
class MirrorDict : public MirrorObject
{
public:
    MirrorDict(PyObject*);

    PyObject* get_item(PyObject* key)
    {
        return PyDict_GetItem(reflect(), key);
    }

private:
    PyDictObject dict;
};

MirrorDict::MirrorDict(PyObject* dict_addr)
{
    if (copy_type(dict_addr, dict))
        throw MirrorError();

    PyDictKeysObject keys;
    if (copy_type(dict.ma_keys, keys))
        throw MirrorError();

    // Compute the full dictionary data size
#if PY_VERSION_HEX >= 0x030b0000
    size_t entry_size =
        keys.dk_kind == DICT_KEYS_UNICODE ? sizeof(PyDictUnicodeEntry) : sizeof(PyDictKeyEntry);
    size_t keys_size = sizeof(PyDictKeysObject) + (1 << keys.dk_log2_index_bytes) +
                       (keys.dk_nentries * entry_size);
#else
    size_t entry_size = sizeof(PyDictKeyEntry);
    size_t keys_size = sizeof(PyDictKeysObject) + (keys.dk_size * sizeof(Py_ssize_t)) +
                       (keys.dk_nentries * entry_size);
#endif
    size_t values_size = dict.ma_values != NULL ? keys.dk_nentries * sizeof(PyObject*) : 0;

    // Allocate the buffer
    ssize_t data_size = keys_size + (keys.dk_nentries * entry_size) + values_size;
    if (data_size < 0 || data_size > (1 << 20))
        throw MirrorError();

    data = std::make_unique<char[]>(data_size);

    // Copy the key data and update the pointer
    if (copy_generic(dict.ma_keys, data.get(), keys_size))
        throw MirrorError();

    dict.ma_keys = (PyDictKeysObject*)data.get();

    if (dict.ma_values != NULL)
    {
        // Copy the value data and update the pointer
        char* values_addr = data.get() + keys_size;
        if (copy_generic(dict.ma_values, keys_size, values_size))
            throw MirrorError();

        dict.ma_values = (PyDictValues*)values_addr;
    }

    reflected = (PyObject*)&dict;
}

// ----------------------------------------------------------------------------
class MirrorSet : public MirrorObject
{
public:
    MirrorSet(PyObject*);
    std::unordered_set<PyObject*> as_unordered_set();

private:
    size_t size;
    PySetObject set;
};

MirrorSet::MirrorSet(PyObject* set_addr)
{
    if (copy_type(set_addr, set))
        throw MirrorError();

    size = set.mask + 1;
    ssize_t table_size = size * sizeof(setentry);
    if (table_size < 0 || table_size > (1 << 20))
        throw MirrorError();

    data = std::make_unique<char[]>(table_size);
    if (copy_generic(set.table, data.get(), table_size))
        throw MirrorError();

    set.table = (setentry*)data.get();

    reflected = (PyObject*)&set;
}

std::unordered_set<PyObject*> MirrorSet::as_unordered_set()
{
    if (data == nullptr)
        throw MirrorError();

    std::unordered_set<PyObject*> uset;

    for (size_t i = 0; i < size; i++)
    {
        auto entry = set.table[i];
        if (entry.key != NULL)
            uset.insert(entry.key);
    }

    return uset;
}


// ============================================================================
// Header: stack_chunk.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.


#define PY_SSIZE_T_CLEAN



// ----------------------------------------------------------------------------

class StackChunkError : public std::exception
{
public:
    const char* what() const noexcept override
    {
        return "Cannot create stack chunk object";
    }
};

// ----------------------------------------------------------------------------
class StackChunk
{
public:
    StackChunk() {}

    inline void update(_PyStackChunk* chunk_addr);
    inline void* resolve(void* frame_addr);
    inline bool is_valid() const;

private:
    void* origin = NULL;
    std::vector<char> data;
    size_t data_capacity = 0;
    std::unique_ptr<StackChunk> previous = nullptr;
};

// ----------------------------------------------------------------------------
void StackChunk::update(_PyStackChunk* chunk_addr)
{
    _PyStackChunk chunk;

    if (copy_type(chunk_addr, chunk))
        throw StackChunkError();

    origin = chunk_addr;
    // if data_capacity is not enough, reallocate.
    if (chunk.size > data_capacity)
    {
        data_capacity = std::max(chunk.size, data_capacity);
        data.resize(data_capacity);
    }

    // Copy the data up until the size of the chunk
    if (copy_generic(chunk_addr, data.data(), chunk.size))
        throw StackChunkError();

    if (chunk.previous != NULL)
    {
        try
        {
            if (previous == nullptr)
                previous = std::make_unique<StackChunk>();
            previous->update((_PyStackChunk*)chunk.previous);
        }
        catch (StackChunkError& e)
        {
            previous = nullptr;
        }
    }
}

// ----------------------------------------------------------------------------
void* StackChunk::resolve(void* address)
{
    // If data is not properly initialized, simply return the address
    if (!is_valid())
    {
        return address;
    }

    _PyStackChunk* chunk = (_PyStackChunk*)data.data();

    // Check if this chunk contains the address
    if (address >= origin && address < (char*)origin + chunk->size)
        return (char*)chunk + ((char*)address - (char*)origin);

    if (previous)
        return previous->resolve(address);

    return address;
}

// ----------------------------------------------------------------------------
bool StackChunk::is_valid() const
{
    return data_capacity > 0 &&
           data.size() > 0 &&
           data.size() >= sizeof(_PyStackChunk) &&
           data.data() != nullptr &&
           origin != nullptr;
}

// ----------------------------------------------------------------------------

std::unique_ptr<StackChunk> stack_chunk = nullptr;


// ============================================================================
// Header: strings.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.


#define PY_SSIZE_T_CLEAN


#ifndef UNWIND_NATIVE_DISABLE
#include <cxxabi.h>
#define UNW_LOCAL_ONLY
#include <libunwind.h>
#endif  // UNWIND_NATIVE_DISABLE



class StringError : public std::exception
{
    const char* what() const noexcept override
    {
        return "StringError";
    }
};

// ----------------------------------------------------------------------------
std::unique_ptr<unsigned char[]> pybytes_to_bytes_and_size(PyObject* bytes_addr,
                                                                  Py_ssize_t* size)
{
    PyBytesObject bytes;

    if (copy_type(bytes_addr, bytes))
        return nullptr;

    *size = bytes.ob_base.ob_size;
    if (*size < 0 || *size > (1 << 20))
        return nullptr;

    auto data = std::make_unique<unsigned char[]>(*size);
    if (copy_generic(((char*)bytes_addr) + offsetof(PyBytesObject, ob_sval), data.get(), *size))
        return nullptr;

    return data;
}

// ----------------------------------------------------------------------------
std::string pyunicode_to_utf8(PyObject* str_addr)
{
    PyUnicodeObject str;
    if (copy_type(str_addr, str))
        throw StringError();

    PyASCIIObject& ascii = str._base._base;

    if (ascii.state.kind != 1)
        throw StringError();

    const char* data = ascii.state.compact ? (const char*)(((uint8_t*)str_addr) + sizeof(ascii))
                                           : (const char*)str._base.utf8;
    if (data == NULL)
        throw StringError();

    Py_ssize_t size = ascii.state.compact ? ascii.length : str._base.utf8_length;
    if (size < 0 || size > 1024)
        throw StringError();

    auto dest = std::string(size, '\0');
    if (copy_generic(data, dest.data(), size))
        throw StringError();

    return dest;
}

// ----------------------------------------------------------------------------

class StringTable : public std::unordered_map<uintptr_t, std::string>
{
public:
    using Key = uintptr_t;

    class Error : public std::exception
    {
    };

    class LookupError : public Error
    {
    };

    static constexpr Key INVALID = 1;
    static constexpr Key UNKNOWN = 2;

    // Python string object
    inline Key key(PyObject* s)
    {
        const std::lock_guard<std::mutex> lock(table_lock);

        auto k = (Key)s;

        if (this->find(k) == this->end())
        {
            try
            {
#if PY_VERSION_HEX >= 0x030c0000
                // The task name might hold a PyLong for deferred task name formatting.
                std::string str = "Task-";
                try
                {
                    str += std::to_string(pylong_to_llong(s));
                }
                catch (LongError&)
                {
                    str = pyunicode_to_utf8(s);
                }
#else
                auto str = pyunicode_to_utf8(s);
#endif
                this->emplace(k, str);
                Renderer::get().string(k, str);
            }
            catch (StringError&)
            {
                throw Error();
            }
        }

        return k;
    };

    // Python string object
    inline Key key_unsafe(PyObject* s)
    {
        const std::lock_guard<std::mutex> lock(table_lock);

        auto k = (Key)s;

        if (this->find(k) == this->end())
        {
#if PY_VERSION_HEX >= 0x030c0000
            // The task name might hold a PyLong for deferred task name formatting.
            auto str = (PyLong_CheckExact(s)) ? "Task-" + std::to_string(PyLong_AsLong(s))
                                              : std::string(PyUnicode_AsUTF8(s));
#else
            auto str = std::string(PyUnicode_AsUTF8(s));
#endif
            this->emplace(k, str);
            Renderer::get().string(k, str);
        }

        return k;
    };

#ifndef UNWIND_NATIVE_DISABLE
    // Native filename by program counter
    inline Key key(unw_word_t pc)
    {
        const std::lock_guard<std::mutex> lock(table_lock);

        auto k = (Key)pc;

        if (this->find(k) == this->end())
        {
            char buffer[32] = {0};
            std::snprintf(buffer, 32, "native@%p", (void*)k);
            this->emplace(k, buffer);
            Renderer::get().string(k, buffer);
        }

        return k;
    }

    // Native scope name by unwinding cursor
    inline Key key(unw_cursor_t& cursor)
    {
        const std::lock_guard<std::mutex> lock(table_lock);

        unw_proc_info_t pi;
        if ((unw_get_proc_info(&cursor, &pi)))
            throw Error();

        auto k = (Key)pi.start_ip;

        if (this->find(k) == this->end())
        {
            unw_word_t offset;  // Ignored. All the information is in the PC anyway.
            char sym[256];
            if (unw_get_proc_name(&cursor, sym, sizeof(sym), &offset))
                throw Error();

            char* name = sym;

            // Try to demangle C++ names
            char* demangled = NULL;
            if (name[0] == '_' && name[1] == 'Z')
            {
                int status;
                demangled = abi::__cxa_demangle(name, NULL, NULL, &status);
                if (status == 0)
                    name = demangled;
            }

            this->emplace(k, name);
            Renderer::get().string(k, name);

            if (demangled)
                std::free(demangled);
        }

        return k;
    }
#endif  // UNWIND_NATIVE_DISABLE

    inline std::string& lookup(Key key)
    {
        const std::lock_guard<std::mutex> lock(table_lock);

        auto it = this->find(key);
        if (it == this->end())
            throw LookupError();

        return it->second;
    };

    StringTable() : std::unordered_map<uintptr_t, std::string>()
    {
        this->emplace(0, "");
        this->emplace(INVALID, "<invalid>");
        this->emplace(UNKNOWN, "<unknown>");
    };

private:
    std::mutex table_lock;
};

// We make this a reference to a heap-allocated object so that we can avoid
// the destruction on exit. We are in charge of cleaning up the object. Note
// that the object will leak, but this is not a problem.
StringTable& string_table = *(new StringTable());


// ============================================================================
// Header: frame.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.


#define PY_SSIZE_T_CLEAN
#if defined __GNUC__ && defined HAVE_STD_ATOMIC
#undef HAVE_STD_ATOMIC
#endif
#if PY_VERSION_HEX >= 0x030c0000
// https://github.com/python/cpython/issues/108216#issuecomment-1696565797
#undef _PyGC_FINALIZED
#endif
#if PY_VERSION_HEX >= 0x030d0000
#define Py_BUILD_CORE
#include <internal/pycore_code.h>
#endif  // PY_VERSION_HEX >= 0x030d0000
#if PY_VERSION_HEX >= 0x030b0000
#define Py_BUILD_CORE
#include <internal/pycore_frame.h>
#endif


#ifndef UNWIND_NATIVE_DISABLE
#include <cxxabi.h>
#define UNW_LOCAL_ONLY
#include <libunwind.h>
#endif  // UNWIND_NATIVE_DISABLE

#if PY_VERSION_HEX >= 0x030b0000
#endif  // PY_VERSION_HEX >= 0x030b0000

// ----------------------------------------------------------------------------
class Frame
{
public:
    using Ref = std::reference_wrapper<Frame>;
    using Ptr = std::unique_ptr<Frame>;
    using Key = uintptr_t;

    // ------------------------------------------------------------------------
    class Error : public std::exception
    {
    public:
        const char* what() const noexcept override
        {
            return "Cannot read frame";
        }
    };

    // ------------------------------------------------------------------------
    class LocationError : public Error
    {
    public:
        const char* what() const noexcept override
        {
            return "Cannot determine frame location information";
        }
    };

    // ------------------------------------------------------------------------
    Key cache_key = 0;
    StringTable::Key filename = 0;
    StringTable::Key name = 0;

    struct _location
    {
        int line = 0;
        int line_end = 0;
        int column = 0;
        int column_end = 0;
    } location;

#if PY_VERSION_HEX >= 0x030b0000
    bool is_entry = false;
#endif

    // ------------------------------------------------------------------------
    Frame(StringTable::Key name) : name(name) {};
    Frame(PyObject* frame);
    Frame(PyCodeObject* code, int lasti);
#ifndef UNWIND_NATIVE_DISABLE
    Frame(unw_cursor_t& cursor, unw_word_t pc);
#endif  // UNWIND_NATIVE_DISABLE

#if PY_VERSION_HEX >= 0x030b0000
    static Frame& read(_PyInterpreterFrame* frame_addr, _PyInterpreterFrame** prev_addr);
#else
    static Frame& read(PyObject* frame_addr, PyObject** prev_addr);
#endif

    static Frame& get(PyCodeObject* code_addr, int lasti);
    static Frame& get(PyObject* frame);
#ifndef UNWIND_NATIVE_DISABLE
    static Frame& get(unw_cursor_t& cursor);
#endif  // UNWIND_NATIVE_DISABLE
    static Frame& get(StringTable::Key name);

private:
    void inline infer_location(PyCodeObject* code, int lasti);
    static inline Key key(PyCodeObject* code, int lasti);
    static inline Key key(PyObject* frame);
};

auto INVALID_FRAME = Frame(StringTable::INVALID);
auto UNKNOWN_FRAME = Frame(StringTable::UNKNOWN);

// We make this a raw pointer to prevent its destruction on exit, since we
// control the lifetime of the cache.
LRUCache<uintptr_t, Frame>* frame_cache = nullptr;
void init_frame_cache(size_t capacity);
void reset_frame_cache();


// ============================================================================
// Header: stacks.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.


#define PY_SSIZE_T_CLEAN


#ifndef UNWIND_NATIVE_DISABLE
#define UNW_LOCAL_ONLY
#include <libunwind.h>
#endif  // UNWIND_NATIVE_DISABLE


// ----------------------------------------------------------------------------

class FrameStack : public std::deque<Frame::Ref>
{
public:
    using Ptr = std::unique_ptr<FrameStack>;
    using Key = Frame::Key;

    // ------------------------------------------------------------------------
    Key key()
    {
        Key h = 0;

        for (auto it = this->begin(); it != this->end(); ++it)
            h = rotl(h) ^ (*it).get().cache_key;

        return h;
    }

    // ------------------------------------------------------------------------
    void render()
    {
        for (auto it = this->rbegin(); it != this->rend(); ++it)
        {
#if PY_VERSION_HEX >= 0x030c0000
            if ((*it).get().is_entry)
                // This is a shim frame so we skip it.
                continue;
#endif
            Renderer::get().render_frame((*it).get());
        }
    }

    // ------------------------------------------------------------------------
    void render_where()
    {
        for (auto it = this->rbegin(); it != this->rend(); ++it)
        {
#if PY_VERSION_HEX >= 0x030c0000
            if ((*it).get().is_entry)
                // This is a shim frame so we skip it.
                continue;
#endif
            WhereRenderer::get().render_frame((*it).get());
        }
    }

private:
    // ------------------------------------------------------------------------
    static inline Frame::Key rotl(Key key)
    {
        return (key << 1) | (key >> (CHAR_BIT * sizeof(key) - 1));
    }

public:
    virtual ~FrameStack() {
        std::cout << "FrameStack destructor" << std::endl;
        print_backtrace();      
    }
};

// ----------------------------------------------------------------------------

extern FrameStack python_stack;
extern FrameStack native_stack;
extern FrameStack interleaved_stack;

// ----------------------------------------------------------------------------
#ifndef UNWIND_NATIVE_DISABLE
    void unwind_native_stack()
    {
    std::cout << "unwinding native stack with real implementation" << std::endl;
    unw_cursor_t cursor;
    unw_context_t context;

    unw_getcontext(&context);
    unw_init_local(&cursor, &context);

    native_stack.clear();

    while (unw_step(&cursor) > 0 && native_stack.size() < max_frames)
    {
        try
        {
            native_stack.push_back(Frame::get(cursor));
        }
        catch (Frame::Error&)
        {
            break;
        }
    }
}
#endif  // UNWIND_NATIVE_DISABLE

// ----------------------------------------------------------------------------
size_t unwind_frame(PyObject* frame_addr, FrameStack& stack)
{
    std::unordered_set<PyObject*> seen_frames;  // Used to detect cycles in the stack
    int count = 0;

    PyObject* current_frame_addr = frame_addr;
    while (current_frame_addr != NULL && stack.size() < max_frames)
    {
        if (seen_frames.find(current_frame_addr) != seen_frames.end())
            break;

        seen_frames.insert(current_frame_addr);

        try
        {
#if PY_VERSION_HEX >= 0x030b0000
            Frame& frame =
                Frame::read(reinterpret_cast<_PyInterpreterFrame*>(current_frame_addr),
                            reinterpret_cast<_PyInterpreterFrame**>(&current_frame_addr));
#else
            Frame& frame = Frame::read(current_frame_addr, &current_frame_addr);
#endif
            stack.push_back(frame);
        }
        catch (Frame::Error& e)
        {
            break;
        }

        count++;
    }

    return count;
}

// ----------------------------------------------------------------------------
size_t unwind_frame_unsafe(PyObject* frame, FrameStack& stack)
{
    std::unordered_set<PyObject*> seen_frames;  // Used to detect cycles in the stack
    int count = 0;

    PyObject* current_frame = frame;
    while (current_frame != NULL && stack.size() < max_frames)
    {
        if (seen_frames.find(current_frame) != seen_frames.end())
            break;

#if PY_VERSION_HEX >= 0x030d0000
        // See the comment in unwind_frame()
        while (current_frame != NULL)
        {
            if (((_PyInterpreterFrame*)current_frame)->f_executable->ob_type == &PyCode_Type)
            {
                break;
            }
            current_frame = (PyObject*)((_PyInterpreterFrame*)current_frame)->previous;
        }

        if (current_frame == NULL)
        {
            break;
        }
#endif  // PY_VERSION_HEX >= 0x030d0000
        count++;

        seen_frames.insert(current_frame);

        stack.push_back(Frame::get(current_frame));

#if PY_VERSION_HEX >= 0x030b0000
        current_frame = (PyObject*)((_PyInterpreterFrame*)current_frame)->previous;
#else
        current_frame = (PyObject*)((PyFrameObject*)current_frame)->f_back;
#endif
    }

    return count;
}

// ----------------------------------------------------------------------------
void unwind_python_stack(PyThreadState* tstate, FrameStack& stack)
{
    stack.clear();
#if PY_VERSION_HEX >= 0x030b0000
    try
    {
        if (stack_chunk == nullptr)
        {
            stack_chunk = std::make_unique<StackChunk>();
        }
        stack_chunk->update((_PyStackChunk*)tstate->datastack_chunk);
    }
    catch (StackChunkError& e)
    {
        stack_chunk = nullptr;
    }
#endif

#if PY_VERSION_HEX >= 0x030d0000
    PyObject* frame_addr = (PyObject*)tstate->current_frame;
#elif PY_VERSION_HEX >= 0x030b0000
    _PyCFrame cframe;
    _PyCFrame* cframe_addr = tstate->cframe;
    if (copy_type(cframe_addr, cframe))
        // TODO: Invalid frame
        return;

    PyObject* frame_addr = (PyObject*)cframe.current_frame;
#else  // Python < 3.11
    PyObject* frame_addr = (PyObject*)tstate->frame;
#endif
    unwind_frame(frame_addr, stack);
}

// ----------------------------------------------------------------------------
void unwind_python_stack_unsafe(PyThreadState* tstate, FrameStack& stack)
{
    stack.clear();
#if PY_VERSION_HEX >= 0x030b0000
    try
    {
        if (stack_chunk == nullptr)
        {
            stack_chunk = std::make_unique<StackChunk>();
        }
        stack_chunk->update((_PyStackChunk*)tstate->datastack_chunk);
    }
    catch (StackChunkError& e)
    {
        stack_chunk = nullptr;
    }
#endif

#if PY_VERSION_HEX >= 0x030d0000
    PyObject* frame_addr = (PyObject*)tstate->current_frame;
#elif PY_VERSION_HEX >= 0x030b0000
    PyObject* frame_addr = (PyObject*)tstate->cframe->current_frame;
#else  // Python < 3.11
    PyObject* frame_addr = (PyObject*)tstate->frame;
#endif
    unwind_frame_unsafe(frame_addr, stack);
}

// ----------------------------------------------------------------------------
void unwind_python_stack(PyThreadState* tstate)
{
    unwind_python_stack(tstate, python_stack);
}

// ----------------------------------------------------------------------------
void interleave_stacks(FrameStack& python_stack)
{
    interleaved_stack.clear();

    auto p = python_stack.rbegin();
    // The last two frames are usually the signal trampoline and the signal
    // handler. We skip them.
    for (auto n = native_stack.rbegin(); n != native_stack.rend() - 2; ++n)
    {
        auto native_frame = *n;

        if (string_table.lookup(native_frame.get().name).find("PyEval_EvalFrameDefault") !=
            std::string::npos)
        {
            if (p == python_stack.rend())
            {
                // We expected a Python frame but we found none, so we report
                // the native frame instead.
                std::cerr << "Expected Python frame(s), found none!" << std::endl;
                interleaved_stack.push_front(native_frame);
            }
            else
            {
                // We skip the PyEval_EvalFrameDefault frame because it is the
                // function that calls the Python code.
#if PY_VERSION_HEX >= 0x030b0000
                int cframe_count = 0;
                while (p != python_stack.rend())
                {
                    // The Python stack will start with an entry frame at the top.
                    // We stop popping at the next entry frame.
                    cframe_count += (*p).get().is_entry;
                    if (cframe_count >= 2)
                        break;

                    interleaved_stack.push_front(*p++);
                }
#else
                interleaved_stack.push_front(*p++);
#endif
            }
        }
        else
            interleaved_stack.push_front(native_frame);
    }

    if (p != python_stack.rend())
    {
        std::cerr << "Python stack not empty after interleaving!" << std::endl;
        while (p != python_stack.rend())
            interleaved_stack.push_front(*p++);
    }
}

// ----------------------------------------------------------------------------
void interleave_stacks()
{
    interleave_stacks(python_stack);
}

// ----------------------------------------------------------------------------
class StackInfo
{
public:
    StringTable::Key task_name;
    bool on_cpu;
    FrameStack stack;

    StackInfo(StringTable::Key task_name, bool on_cpu) : task_name(task_name), on_cpu(on_cpu) {}
};

// ----------------------------------------------------------------------------
// This table is used to store entire stacks and index them by key. This is
// used when profiling memory events to account for deallocations.
class StackTable
{
public:
    // ------------------------------------------------------------------------
    FrameStack::Key inline store(FrameStack::Ptr stack)
    {
        std::lock_guard<std::mutex> lock(this->lock);

        auto stack_key = stack->key();

        auto stack_entry = table.find(stack_key);
        if (stack_entry == table.end())
        {
            table.emplace(stack_key, std::move(stack));
        }
        else
        {
            // TODO: Check for collisions.
        }

        return stack_key;
    }

    // ------------------------------------------------------------------------
    FrameStack& retrieve(FrameStack::Key stack_key)
    {
        std::lock_guard<std::mutex> lock(this->lock);

        return *table.find(stack_key)->second;
    }

    // ------------------------------------------------------------------------
    void clear()
    {
        std::lock_guard<std::mutex> lock(this->lock);

        table.clear();
    }

private:
    std::unordered_map<FrameStack::Key, std::unique_ptr<FrameStack>> table;
    std::mutex lock;
};

// ----------------------------------------------------------------------------
// We make this a reference to a heap-allocated object so that we can avoid
// the destruction on exit. We are in charge of cleaning up the object. Note
// that the object will leak, but this is not a problem.
auto& stack_table = *(new StackTable());


// ============================================================================
// Header: greenlets.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2025 Gabriele N. Tornetta <phoenix1987@gmail.com>.


#define Py_BUILD_CORE




#define FRAME_NOT_SET Py_False  // Sentinel for frame cell


class GreenletInfo
{
public:
    typedef std::unique_ptr<GreenletInfo> Ptr;
    typedef std::reference_wrapper<GreenletInfo> Ref;
    typedef uintptr_t ID;

    ID greenlet_id = 0;
    StringTable::Key name;
    PyObject* frame = NULL;

    GreenletInfo(ID id, PyObject* frame, StringTable::Key name)
        : greenlet_id(id), frame(frame), name(name)
    {
    }

    int unwind(PyObject*, PyThreadState*, FrameStack&);
};

// ----------------------------------------------------------------------------

int GreenletInfo::unwind(PyObject* frame, PyThreadState* tstate, FrameStack& stack)
{
    PyObject* frame_addr = NULL;
#if PY_VERSION_HEX >= 0x030d0000
    frame_addr =
        frame == Py_None
            ? (PyObject*)tstate->current_frame
            : reinterpret_cast<PyObject*>(reinterpret_cast<struct _frame*>(frame)->f_frame);
#elif PY_VERSION_HEX >= 0x030b0000
    if (frame == Py_None)
    {
        _PyCFrame cframe;
        _PyCFrame* cframe_addr = tstate->cframe;
        if (copy_type(cframe_addr, cframe))
            // TODO: Invalid frame
            return 0;

        frame_addr = (PyObject*)cframe.current_frame;
    }
    else
    {
        frame_addr = reinterpret_cast<PyObject*>(reinterpret_cast<struct _frame*>(frame)->f_frame);
    }

#else  // Python < 3.11
    frame_addr = frame == Py_None ? (PyObject*)tstate->frame : frame;
#endif
    auto count = unwind_frame(frame_addr, stack);

    stack.push_back(Frame::get(name));

    return count + 1;  // We add an extra count for the frame with the greenlet
                       // name.
}

// ----------------------------------------------------------------------------

// We make this a reference to a heap-allocated object so that we can avoid
// the destruction on exit. We are in charge of cleaning up the object. Note
// that the object will leak, but this is not a problem.
std::unordered_map<GreenletInfo::ID, GreenletInfo::Ptr>& greenlet_info_map =
    *(new std::unordered_map<GreenletInfo::ID, GreenletInfo::Ptr>());

// maps greenlets to their parent
std::unordered_map<GreenletInfo::ID, GreenletInfo::ID>& greenlet_parent_map =
    *(new std::unordered_map<GreenletInfo::ID, GreenletInfo::ID>());

// maps threads to any currently active greenlets
std::unordered_map<uintptr_t, GreenletInfo::ID>& greenlet_thread_map =
    *(new std::unordered_map<uintptr_t, GreenletInfo::ID>());

std::mutex greenlet_info_map_lock;

// ----------------------------------------------------------------------------

std::vector<std::unique_ptr<StackInfo>> current_greenlets;

// ----------------------------------------------------------------------------


// ============================================================================
// Header: signals.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.


#define PY_SSIZE_T_CLEAN



// ----------------------------------------------------------------------------

std::mutex sigprof_handler_lock;

// ----------------------------------------------------------------------------
void sigprof_handler([[maybe_unused]] int signum)
{
#ifndef UNWIND_NATIVE_DISABLE
    unwind_native_stack();
#else
    std::cout << "native unwinding is disabled" << std::endl;
#endif  // UNWIND_NATIVE_DISABLE
    unwind_python_stack(current_tstate);
    // NOTE: Native stacks for tasks is non-trivial, so we skip it for now.

    sigprof_handler_lock.unlock();
}

// ----------------------------------------------------------------------------
void sigquit_handler([[maybe_unused]] int signum)
{
    // Wake up the where thread
    std::lock_guard<std::mutex> lock(where_lock);
    where_cv.notify_one();
}

// ----------------------------------------------------------------------------
void install_signals()
{
    signal(SIGQUIT, sigquit_handler);

    if (native)
        signal(SIGPROF, sigprof_handler);
}

// ----------------------------------------------------------------------------
void restore_signals()
{
    signal(SIGQUIT, SIG_DFL);

    if (native)
        signal(SIGPROF, SIG_DFL);
}


// ============================================================================
// Header: tasks.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.


#define PY_SSIZE_T_CLEAN

#if PY_VERSION_HEX >= 0x030b0000
#include <cpython/genobject.h>

#define Py_BUILD_CORE
#if PY_VERSION_HEX >= 0x030d0000
#include <opcode.h>
#else
#include <internal/pycore_opcode.h>
#endif  // PY_VERSION_HEX >= 0x030d0000
#else
#include <genobject.h>
#include <opcode.h>
#endif  // PY_VERSION_HEX >= 0x30b0000




class GenInfo
{
public:
    typedef std::unique_ptr<GenInfo> Ptr;

    class Error : public std::exception
    {
    public:
        const char* what() const noexcept override
        {
            return "Cannot create generator info object";
        }
    };

    PyObject* origin = NULL;
    PyObject* frame = NULL;

    GenInfo::Ptr await = nullptr;

    bool is_running = false;

    GenInfo(PyObject* gen_addr);
};

GenInfo::GenInfo(PyObject* gen_addr)
{
    PyGenObject gen;

    if (copy_type(gen_addr, gen) || !PyCoro_CheckExact(&gen))
        throw Error();

    origin = gen_addr;

#if PY_VERSION_HEX >= 0x030b0000
    // The frame follows the generator object
    frame = (gen.gi_frame_state == FRAME_CLEARED)
                ? NULL
                : (PyObject*)((char*)gen_addr + offsetof(PyGenObject, gi_iframe));
#else
    frame = (PyObject*)gen.gi_frame;
#endif

    PyFrameObject f;
    if (copy_type(frame, f))
        throw Error();

    PyObject* yf = (frame != NULL ? PyGen_yf(&gen, frame) : NULL);
    if (yf != NULL && yf != gen_addr)
    {
        try
        {
            await = std::make_unique<GenInfo>(yf);
        }
        catch (GenInfo::Error&)
        {
            await = nullptr;
        }
    }

#if PY_VERSION_HEX >= 0x030b0000
    is_running = (gen.gi_frame_state == FRAME_EXECUTING);
#elif PY_VERSION_HEX >= 0x030a0000
    is_running = (frame != NULL) ? _PyFrame_IsExecuting(&f) : false;
#else
    is_running = gen.gi_running;
#endif
}

// ----------------------------------------------------------------------------

class TaskInfo
{
public:
    typedef std::unique_ptr<TaskInfo> Ptr;
    typedef std::reference_wrapper<TaskInfo> Ref;

    class Error : public std::exception
    {
    public:
        const char* what() const noexcept override
        {
            return "Cannot create task info object";
        }
    };

    class GeneratorError : public Error
    {
    public:
        const char* what() const noexcept override
        {
            return "Cannot create generator info object";
        }
    };

    PyObject* origin = NULL;
    PyObject* loop = NULL;

    GenInfo::Ptr coro = nullptr;

    StringTable::Key name;

    // Information to reconstruct the async stack as best as we can
    TaskInfo::Ptr waiter = nullptr;

    TaskInfo(TaskObj*);

    static TaskInfo current(PyObject*);
    inline size_t unwind(FrameStack&);
};

std::unordered_map<PyObject*, PyObject*> task_link_map;
std::mutex task_link_map_lock;

// ----------------------------------------------------------------------------
TaskInfo::TaskInfo(TaskObj* task_addr)
{
    TaskObj task;
    if (copy_type(task_addr, task))
        throw Error();

    try
    {
        coro = std::make_unique<GenInfo>(task.task_coro);
    }
    catch (GenInfo::Error&)
    {
        throw GeneratorError();
    }

    origin = (PyObject*)task_addr;

    try
    {
        name = string_table.key(task.task_name);
    }
    catch (StringTable::Error&)
    {
        throw Error();
    }

    loop = task.task_loop;

    if (task.task_fut_waiter)
    {
        try
        {
            waiter =
                std::make_unique<TaskInfo>((TaskObj*)task.task_fut_waiter);  // TODO: Make lazy?
        }
        catch (TaskInfo::Error&)
        {
            waiter = nullptr;
        }
    }
}

// ----------------------------------------------------------------------------
TaskInfo TaskInfo::current(PyObject* loop)
{
    if (loop == NULL)
        throw Error();

    try
    {
        MirrorDict current_tasks_dict(asyncio_current_tasks);
        PyObject* task = current_tasks_dict.get_item(loop);
        if (task == NULL)
            throw Error();

        return TaskInfo((TaskObj*)task);
    }
    catch (MirrorError& e)
    {
        throw Error();
    }
}

// ----------------------------------------------------------------------------
// TODO: Make this a "for_each_task" function?
std::vector<TaskInfo::Ptr> get_all_tasks(PyObject* loop)
{
    std::vector<TaskInfo::Ptr> tasks;
    if (loop == NULL)
        return tasks;

    try
    {
        MirrorSet scheduled_tasks_set(asyncio_scheduled_tasks);
        auto scheduled_tasks = scheduled_tasks_set.as_unordered_set();

        for (auto task_wr_addr : scheduled_tasks)
        {
            PyWeakReference task_wr;
            if (copy_type(task_wr_addr, task_wr))
                continue;

            try
            {
                auto task_info = std::make_unique<TaskInfo>((TaskObj*)task_wr.wr_object);
                if (task_info->loop == loop)
                    tasks.push_back(std::move(task_info));
            }
            catch (TaskInfo::Error& e)
            {
                // We failed to get this task but we keep going
            }
        }

        if (asyncio_eager_tasks != NULL)
        {
            MirrorSet eager_tasks_set(asyncio_eager_tasks);
            auto eager_tasks = eager_tasks_set.as_unordered_set();

            for (auto task_addr : eager_tasks)
            {
                try
                {
                    auto task_info = std::make_unique<TaskInfo>((TaskObj*)task_addr);
                    if (task_info->loop == loop)
                        tasks.push_back(std::move(task_info));
                }
                catch (TaskInfo::Error& e)
                {
                    // We failed to get this task but we keep going
                }
            }
        }

        return tasks;
    }
    catch (MirrorError& e)
    {
        throw TaskInfo::Error();
    }
}

// ----------------------------------------------------------------------------

std::vector<std::unique_ptr<StackInfo>> current_tasks;

// ----------------------------------------------------------------------------

size_t TaskInfo::unwind(FrameStack& stack)
{
    // TODO: Check for running task.
    std::stack<PyObject*> coro_frames;

    // Unwind the coro chain
    for (auto coro = this->coro.get(); coro != NULL; coro = coro->await.get())
    {
        if (coro->frame != NULL)
            coro_frames.push(coro->frame);
    }

    int count = 0;

    // Unwind the coro frames
    while (!coro_frames.empty())
    {
        PyObject* frame = coro_frames.top();
        coro_frames.pop();

        count += unwind_frame(frame, stack);
    }

    return count;
}


// ============================================================================
// Header: threads.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.


#define Py_BUILD_CORE


#if defined PL_LINUX
#include <time.h>
#elif defined PL_DARWIN
#include <mach/clock.h>
#include <mach/mach.h>
#endif


class ThreadInfo
{
public:
    using Ptr = std::unique_ptr<ThreadInfo>;

    class Error : public std::exception
    {
    public:
        const char* what() const noexcept override
        {
            return "Cannot create thread info object";
        }
    };

    class CpuTimeError : public Error
    {
    public:
        const char* what() const noexcept override
        {
            return "Cannot update CPU time";
        }
    };

    uintptr_t thread_id;
    unsigned long native_id;

    std::string name;

#if defined PL_LINUX
    clockid_t cpu_clock_id;
#elif defined PL_DARWIN
    mach_port_t mach_port;
#endif
    microsecond_t cpu_time;

    uintptr_t asyncio_loop = 0;

    void update_cpu_time();
    bool is_running();

    void sample(int64_t, PyThreadState*, microsecond_t);
    void unwind(PyThreadState*);

    // ------------------------------------------------------------------------
    ThreadInfo(uintptr_t thread_id, unsigned long native_id, const char* name)
        : thread_id(thread_id), native_id(native_id), name(name)
    {
#if defined PL_LINUX
        if (pthread_getcpuclockid((pthread_t)thread_id, &cpu_clock_id))
            throw ThreadInfo::Error{};

#elif defined PL_DARWIN
        // pthread_mach_thread_np does not return a status code; the behaviour is undefined
        // if thread_id is invalid.
        mach_port = pthread_mach_thread_np((pthread_t)thread_id);
#endif
        update_cpu_time();
    };

private:
    void unwind_tasks();
    void unwind_greenlets(PyThreadState*, unsigned long);
};

void ThreadInfo::update_cpu_time()
{
#if defined PL_LINUX
    struct timespec ts;
    if (clock_gettime(cpu_clock_id, &ts))
        throw ThreadInfo::CpuTimeError{};

    this->cpu_time = TS_TO_MICROSECOND(ts);
#elif defined PL_DARWIN
    thread_basic_info_data_t info;
    mach_msg_type_number_t count = THREAD_BASIC_INFO_COUNT;
    kern_return_t kr =
        thread_info((thread_act_t)this->mach_port, THREAD_BASIC_INFO, (thread_info_t)&info, &count);

    if (kr != KERN_SUCCESS)
        throw ThreadInfo::CpuTimeError{};

    if (info.flags & TH_FLAGS_IDLE)
        return;

    this->cpu_time = TV_TO_MICROSECOND(info.user_time) + TV_TO_MICROSECOND(info.system_time);
#endif
}

bool ThreadInfo::is_running()
{
#if defined PL_LINUX
    struct timespec ts1, ts2;

    // Get two back-to-back times
    if (clock_gettime(cpu_clock_id, &ts1) != 0)
        return false;
    if (clock_gettime(cpu_clock_id, &ts2) != 0)
        return false;

    // If the CPU time has advanced, the thread is running
    return (ts1.tv_sec != ts2.tv_sec || ts1.tv_nsec != ts2.tv_nsec);

#elif defined PL_DARWIN
    thread_basic_info_data_t info;
    mach_msg_type_number_t count = THREAD_BASIC_INFO_COUNT;
    kern_return_t kr =
        thread_info((thread_act_t)this->mach_port, THREAD_BASIC_INFO, (thread_info_t)&info, &count);

    if (kr != KERN_SUCCESS)
        return false;

    return info.run_state == TH_STATE_RUNNING;

#endif
}

// ----------------------------------------------------------------------------

// We make this a reference to a heap-allocated object so that we can avoid
// the destruction on exit. We are in charge of cleaning up the object. Note
// that the object will leak, but this is not a problem.
std::unordered_map<uintptr_t, ThreadInfo::Ptr>& thread_info_map =
    *(new std::unordered_map<uintptr_t, ThreadInfo::Ptr>());  // indexed by thread_id

std::mutex thread_info_map_lock;

// ----------------------------------------------------------------------------
void ThreadInfo::unwind(PyThreadState* tstate)
{
    if (native)
    {
        // Lock on the signal handler. Will get unlocked once the handler is
        // done unwinding the native stack.
        const std::lock_guard<std::mutex> guard(sigprof_handler_lock);

        // Pass the current thread state to the signal handler. This is needed
        // to unwind the Python stack from within it.
        current_tstate = tstate;

        // Send a signal to the thread to unwind its native stack.
        pthread_kill((pthread_t)tstate->thread_id, SIGPROF);

        // Lock to wait for the signal handler to finish unwinding the native
        // stack. Release the lock immediately after so that it is available
        // for the next thread.
        sigprof_handler_lock.lock();
    }
    else
    {
        unwind_python_stack(tstate);
        if (asyncio_loop)
        {
            try
            {
                unwind_tasks();
            }
            catch (TaskInfo::Error&)
            {
                // We failed to unwind tasks
            }
        }

        // We make the assumption that gevent and asyncio are not mixed
        // together to keep the logic here simple. We can always revisit this
        // should there be a substantial demand for it.
        unwind_greenlets(tstate, native_id);
    }
}

// ----------------------------------------------------------------------------
void ThreadInfo::unwind_tasks()
{
    std::vector<TaskInfo::Ref> leaf_tasks;
    std::unordered_set<PyObject*> parent_tasks;
    std::unordered_map<PyObject*, TaskInfo::Ref> waitee_map;  // Indexed by task origin
    std::unordered_map<PyObject*, TaskInfo::Ref> origin_map;  // Indexed by task origin

    auto all_tasks = get_all_tasks((PyObject*)asyncio_loop);

    {
        std::lock_guard<std::mutex> lock(task_link_map_lock);

        // Clean up the task_link_map. Remove entries associated to tasks that
        // no longer exist.
        std::unordered_set<PyObject*> all_task_origins;
        std::transform(all_tasks.cbegin(), all_tasks.cend(),
                       std::inserter(all_task_origins, all_task_origins.begin()),
                       [](const TaskInfo::Ptr& task) { return task->origin; });

        std::vector<PyObject*> to_remove;
        for (auto kv : task_link_map)
        {
            if (all_task_origins.find(kv.first) == all_task_origins.end())
                to_remove.push_back(kv.first);
        }
        for (auto key : to_remove)
            task_link_map.erase(key);

        // Determine the parent tasks from the gather links.
        std::transform(task_link_map.cbegin(), task_link_map.cend(),
                       std::inserter(parent_tasks, parent_tasks.begin()),
                       [](const std::pair<PyObject*, PyObject*>& kv) { return kv.second; });
    }

    for (auto& task : all_tasks)
    {
        origin_map.emplace(task->origin, std::ref(*task));

        if (task->waiter != NULL)
            waitee_map.emplace(task->waiter->origin, std::ref(*task));
        else if (parent_tasks.find(task->origin) == parent_tasks.end())
        {
            if (cpu && ignore_non_running_threads && !task->coro->is_running)
            {
                // This task is not running, so we skip it if we are
                // interested in just CPU time.
                continue;
            }
            leaf_tasks.push_back(std::ref(*task));
        }
    }

    for (auto& task : leaf_tasks)
    {
        bool on_cpu = task.get().coro->is_running;
        auto stack_info = std::make_unique<StackInfo>(task.get().name, on_cpu);
        auto& stack = stack_info->stack;
        for (auto current_task = task;;)
        {
            auto& task = current_task.get();

            size_t stack_size = task.unwind(stack);

            if (on_cpu)
            {
                // Undo the stack unwinding
                // TODO[perf]: not super-efficient :(
                for (size_t i = 0; i < stack_size; i++)
                    stack.pop_back();

                // Instead we get part of the thread stack
                FrameStack temp_stack;
                size_t nframes =
                    (python_stack.size() > stack_size) ? python_stack.size() - stack_size : 0;
                for (size_t i = 0; i < nframes; i++)
                {
                    auto python_frame = python_stack.front();
                    temp_stack.push_front(python_frame);
                    python_stack.pop_front();
                }
                while (!temp_stack.empty())
                {
                    stack.push_front(temp_stack.front());
                    temp_stack.pop_front();
                }
            }

            // Add the task name frame
            stack.push_back(Frame::get(task.name));

            // Get the next task in the chain
            PyObject* task_origin = task.origin;
            if (waitee_map.find(task_origin) != waitee_map.end())
            {
                current_task = waitee_map.find(task_origin)->second;
                continue;
            }

            {
                // Check for, e.g., gather links
                std::lock_guard<std::mutex> lock(task_link_map_lock);

                if (task_link_map.find(task_origin) != task_link_map.end() &&
                    origin_map.find(task_link_map[task_origin]) != origin_map.end())
                {
                    current_task = origin_map.find(task_link_map[task_origin])->second;
                    continue;
                }
            }

            break;
        }

        // Finish off with the remaining thread stack
        for (auto p = python_stack.begin(); p != python_stack.end(); p++)
            stack.push_back(*p);

        current_tasks.push_back(std::move(stack_info));
    }
}

// ----------------------------------------------------------------------------
void ThreadInfo::unwind_greenlets(PyThreadState* tstate, unsigned long native_id)
{
    const std::lock_guard<std::mutex> guard(greenlet_info_map_lock);

    if (greenlet_thread_map.find(native_id) == greenlet_thread_map.end())
        return;

    std::unordered_set<GreenletInfo::ID> parent_greenlets;

    // Collect all parent greenlets
    std::transform(
        greenlet_parent_map.cbegin(), greenlet_parent_map.cend(),
        std::inserter(parent_greenlets, parent_greenlets.begin()),
        [](const std::pair<GreenletInfo::ID, GreenletInfo::ID>& kv) { return kv.second; });

    // Unwind the leaf greenlets
    for (auto& greenlet_info : greenlet_info_map)
    {
        auto greenlet_id = greenlet_info.first;
        auto& greenlet = greenlet_info.second;

        if (parent_greenlets.find(greenlet_id) != parent_greenlets.end())
            continue;

        auto frame = greenlet->frame;
        if (frame == FRAME_NOT_SET)
        {
            // The greenlet has not been started yet or has finished
            continue;
        }

        bool on_cpu = frame == Py_None;
        if (cpu && ignore_non_running_threads && !on_cpu)
        {
            // Only the currently-running greenlet has a None in its frame
            // cell. If we are interested in CPU time, we skip all greenlets
            // that have an actual frame, as they are not running.
            continue;
        }

        auto stack_info = std::make_unique<StackInfo>(greenlet->name, on_cpu);
        auto& stack = stack_info->stack;

        greenlet->unwind(frame, tstate, stack);

        // Unwind the parent greenlets
        for (;;)
        {
            auto parent_greenlet_info = greenlet_parent_map.find(greenlet_id);
            if (parent_greenlet_info == greenlet_parent_map.end())
                break;

            auto parent_greenlet_id = parent_greenlet_info->second;

            auto parent_greenlet = greenlet_info_map.find(parent_greenlet_id);
            if (parent_greenlet == greenlet_info_map.end())
                break;

            auto parent_frame = parent_greenlet->second->frame;
            if (parent_frame == FRAME_NOT_SET || parent_frame == Py_None)
                break;

            parent_greenlet->second->unwind(parent_frame, tstate, stack);

            // Move up the greenlet chain
            greenlet_id = parent_greenlet_id;
        }

        current_greenlets.push_back(std::move(stack_info));
    }
}

// ----------------------------------------------------------------------------
void ThreadInfo::sample(int64_t iid, PyThreadState* tstate, microsecond_t delta)
{
    Renderer::get().render_thread_begin(tstate, name, delta, thread_id, native_id);

    if (cpu)
    {
        microsecond_t previous_cpu_time = cpu_time;
        update_cpu_time();

        bool running = is_running();
        if (!running && ignore_non_running_threads)
        {
            return;
        }

        Renderer::get().render_cpu_time(running ? cpu_time - previous_cpu_time : 0);
    }

    unwind(tstate);

    // Asyncio tasks
    if (current_tasks.empty())
    {
        // If we don't have any asyncio tasks, we check that we don't have any
        // greenlets either. In this case, we print the ordinary thread stack.
        // With greenlets, we recover the thread stack from the active greenlet,
        // so if we don't skip here we would have a double print.
        if (current_greenlets.empty())
        {
            // Print the PID and thread name
            Renderer::get().render_stack_begin(pid, iid, name);
            // Print the stack
            if (native)
            {
                interleave_stacks();
                interleaved_stack.render();
            }
            else
                python_stack.render();

            Renderer::get().render_stack_end(MetricType::Time, delta);
        }
    }
    else
    {
        for (auto& task_stack_info : current_tasks)
        {
            Renderer::get().render_task_begin(string_table.lookup(task_stack_info->task_name),
                                              task_stack_info->on_cpu);
            Renderer::get().render_stack_begin(pid, iid, name);
            if (native)
            {
                // NOTE: These stacks might be non-sensical, especially with
                // Python < 3.11.
                interleave_stacks(task_stack_info->stack);
                interleaved_stack.render();
            }
            else
                task_stack_info->stack.render();

            Renderer::get().render_stack_end(MetricType::Time, delta);
        }

        current_tasks.clear();
    }

    // Greenlet stacks
    if (!current_greenlets.empty())
    {
        for (auto& greenlet_stack : current_greenlets)
        {
            Renderer::get().render_task_begin(string_table.lookup(greenlet_stack->task_name),
                                              greenlet_stack->on_cpu);
            Renderer::get().render_stack_begin(pid, iid, name);

            auto& stack = greenlet_stack->stack;
            if (native)
            {
                // NOTE: These stacks might be non-sensical, especially with
                // Python < 3.11.
                interleave_stacks(stack);
                interleaved_stack.render();
            }
            else
                stack.render();

            Renderer::get().render_stack_end(MetricType::Time, delta);
        }

        current_greenlets.clear();
    }
}

// ----------------------------------------------------------------------------
void for_each_thread(InterpreterInfo& interp,
                            std::function<void(PyThreadState*, ThreadInfo&)> callback)
{
    std::unordered_set<PyThreadState*> threads;
    std::unordered_set<PyThreadState*> seen_threads;

    threads.clear();
    seen_threads.clear();

    // Start from the thread list head
    threads.insert((PyThreadState*)interp.tstate_head);

    while (!threads.empty())
    {
        // Pop the next thread
        PyThreadState* tstate_addr = *threads.begin();
        threads.erase(threads.begin());

        // Mark the thread as seen
        seen_threads.insert(tstate_addr);

        // Since threads can be created and destroyed at any time, we make
        // a copy of the structure before trying to read its fields.
        PyThreadState tstate;
        if (copy_type(tstate_addr, tstate))
            // We failed to copy the thread so we skip it.
            continue;

        // Enqueue the unseen threads that we can reach from this thread.
        if (tstate.next != NULL && seen_threads.find(tstate.next) == seen_threads.end())
            threads.insert(tstate.next);
        if (tstate.prev != NULL && seen_threads.find(tstate.prev) == seen_threads.end())
            threads.insert(tstate.prev);

        {
            const std::lock_guard<std::mutex> guard(thread_info_map_lock);

            if (thread_info_map.find(tstate.thread_id) == thread_info_map.end())
            {
                // If the threading module was not imported in the target then
                // we mistakenly take the hypno thread as the main thread. We
                // assume that any missing thread is the actual main thread,
                // provided we don't already have a thread with the name
                // "MainThread". Note that this can also happen on shutdown, so
                // we need to avoid doing anything in that case.
#if PY_VERSION_HEX >= 0x030b0000
                auto native_id = tstate.native_thread_id;
#else
                auto native_id = getpid();
#endif
                try
                {
                    bool main_thread_tracked = false;
                    for (auto& kv : thread_info_map)
                    {
                        if (kv.second->name == "MainThread")
                        {
                            main_thread_tracked = true;
                            break;
                        }
                    }
                    if (main_thread_tracked)
                        continue;

                    thread_info_map.emplace(
                        tstate.thread_id,
                        std::make_unique<ThreadInfo>(tstate.thread_id, native_id, "MainThread"));
                }
                catch (ThreadInfo::Error&)
                {
                    // We failed to create the thread info object so we skip it.
                    // We'll likely try again later with the valid thread
                    // information.
                    continue;
                }
            }

            // Call back with the thread state and thread info.
            callback(&tstate, *thread_info_map.find(tstate.thread_id)->second);
        }
    }
}


// ============================================================================
// Header: memory.h
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.






// ----------------------------------------------------------------------------
class ResidentMemoryTracker
{
public:
    size_t size;

    // ------------------------------------------------------------------------
    ResidentMemoryTracker()
    {
        update();
    }

    // ------------------------------------------------------------------------
    bool inline check()
    {
        size_t old_size = size;
        update();
        return size != old_size;
    }

private:
    // ------------------------------------------------------------------------
    void inline update()
    {
        struct rusage usage;
        getrusage(RUSAGE_SELF, &usage);
        size = usage.ru_maxrss;
    }
};

ResidentMemoryTracker rss_tracker;

// ----------------------------------------------------------------------------

class MemoryStats
{
public:
    int64_t iid;
    std::string thread_name;

    FrameStack::Key stack;

    size_t count;
    ssize_t size;

    // ------------------------------------------------------------------------
    MemoryStats(int iid, std::string thread_name, FrameStack::Key stack, size_t count, size_t size)
        : iid(iid), thread_name(thread_name), stack(stack), count(count), size(size)
    {
    }

    // ------------------------------------------------------------------------
    void inline render()
    {
        Renderer::get().render_stack_begin(pid, iid, thread_name);

        stack_table.retrieve(stack).render();

        Renderer::get().render_stack_end(MetricType::Memory, size);
    }
};

// ----------------------------------------------------------------------------
struct MemoryTableEntry
{
    FrameStack::Key stack;
    size_t size;
};

// ----------------------------------------------------------------------------
class MemoryTable : public std::unordered_map<void*, MemoryTableEntry>
{
public:
    // ------------------------------------------------------------------------
    void link(void* address, FrameStack::Key stack, size_t size)
    {
        std::lock_guard<std::mutex> lock(this->lock);

        this->emplace(address, (MemoryTableEntry){stack, size});
    }

    // ------------------------------------------------------------------------
    std::optional<MemoryTableEntry> unlink(void* address)
    {
        std::lock_guard<std::mutex> lock(this->lock);

        auto it = this->find(address);

        if (it != this->end())
        {
            auto entry = it->second;
            erase(it);
            return {entry};
        }

        return {};
    }

private:
    std::mutex lock;
};

// ----------------------------------------------------------------------------
class StackStats
{
public:
    // ------------------------------------------------------------------------
    void inline update(PyThreadState* tstate, FrameStack::Key stack, size_t size)
    {
        std::lock_guard<std::mutex> lock(this->lock);

        auto stack_entry = map.find(stack);

        if (stack_entry == map.end())
        {
            if (tstate == NULL)
                // Invalid thread state, nothing we can do.
                return;

            std::lock_guard<std::mutex> ti_lock(thread_info_map_lock);

            // Map the memory address with the stack so that we can account for
            // the deallocations.
            map.emplace(stack,
                        MemoryStats(tstate->interp->id, thread_info_map[tstate->thread_id]->name,
                                    stack, 1, size));
        }
        else
        {
            stack_entry->second.count++;
            stack_entry->second.size += size;
        }
    }

    // ------------------------------------------------------------------------
    void inline update(MemoryTableEntry& entry)
    {
        std::lock_guard<std::mutex> lock(this->lock);

        auto stack_entry = map.find(entry.stack);

        if (stack_entry != map.end())
            stack_entry->second.size -= entry.size;
    }

    // ------------------------------------------------------------------------
    void flush()
    {
        std::lock_guard<std::mutex> lock(this->lock);

        for (auto& entry : map)
        {
            // Emit non-trivial stack stats only
            if (entry.second.size != 0)
                entry.second.render();

            // Reset the stats
            entry.second.size = 0;
            entry.second.count = 0;
        }
    }

    // ------------------------------------------------------------------------
    void clear()
    {
        std::lock_guard<std::mutex> lock(this->lock);

        map.clear();
    }

private:
    std::mutex lock;
    std::unordered_map<FrameStack::Key, MemoryStats> map;
};

// ----------------------------------------------------------------------------

// We make this a reference to a heap-allocated object so that we can avoid
// the destruction on exit. We are in charge of cleaning up the object. Note
// that the object will leak, but this is not a problem.
auto& stack_stats = *(new StackStats());
auto& memory_table = *(new MemoryTable());

// ----------------------------------------------------------------------------
void general_alloc(void* address, size_t size)
{
    auto stack = std::make_unique<FrameStack>();
    auto* tstate = PyThreadState_Get();  // DEV: This should be called with the GIL held

    // DEV: We unwind the stack by reading the data out of live Python objects.
    // This works under the assumption that the objects/data structures we are
    // interested in belong to the thread whose stack we are unwinding.
    // Therefore, we expect these structures to remain valid and essentially
    // immutable for the duration of the unwinding process, which happens
    // in-line with the allocation within the calling thread.
    unwind_python_stack_unsafe(tstate, *stack);

    // Store the stack and get its key for reference
    // TODO: Handle collision exception
    auto stack_key = stack_table.store(std::move(stack));

    // Link the memory address with the stack
    memory_table.link(address, stack_key, size);

    // Update the stack stats
    stack_stats.update(tstate, stack_key, size);
}

// ----------------------------------------------------------------------------
void general_free(void* address)
{
    // Retrieve the stack that made the allocation
    if (auto entry = memory_table.unlink(address))
        // Update the stack stats
        stack_stats.update(*entry);
}

// ----------------------------------------------------------------------------
void* echion_malloc(void* ctx, size_t n)
{
    auto* alloc = (PyMemAllocatorEx*)ctx;

    // Make the actual allocation
    auto address = alloc->malloc(alloc->ctx, n);

    // Handle the allocation event
    if (address != NULL)
        general_alloc(address, n);

    return address;
}

// ----------------------------------------------------------------------------
void* echion_calloc(void* ctx, size_t nelem, size_t elsize)
{
    auto* alloc = (PyMemAllocatorEx*)ctx;

    // Make the actual allocation
    auto address = alloc->calloc(alloc->ctx, nelem, elsize);

    // Handle the allocation event
    if (address != NULL)
        general_alloc(address, nelem * elsize);

    return address;
}

// ----------------------------------------------------------------------------
void* echion_realloc(void* ctx, void* p, size_t n)
{
    auto* alloc = (PyMemAllocatorEx*)ctx;

    // Model this as a deallocation followed by an allocation
    if (p != NULL)
        general_free(p);

    auto address = alloc->realloc(alloc->ctx, p, n);

    if (address != NULL)
        general_alloc(address, n);

    return address;
}

// ----------------------------------------------------------------------------
void echion_free(void* ctx, void* p)
{
    auto* alloc = (PyMemAllocatorEx*)ctx;

    // Handle the deallocation event
    if (p != NULL)
        general_free(p);

    alloc->free(alloc->ctx, p);
}

// ----------------------------------------------------------------------------

// DEV: We define this macro on the basis of the knowledge that the domains are
//      defined as an enum.
#define ALLOC_DOMAIN_COUNT 3

PyMemAllocatorEx original_allocators[ALLOC_DOMAIN_COUNT];
PyMemAllocatorEx echion_allocator = {NULL, echion_malloc, echion_calloc, echion_realloc,
                                            echion_free};

// ----------------------------------------------------------------------------
void setup_memory()
{
    for (int i = 0; i < ALLOC_DOMAIN_COUNT; i++)
    {
        // Save the original allocators
        PyMem_GetAllocator(static_cast<PyMemAllocatorDomain>(i), &original_allocators[i]);

        // Install the new allocators
        echion_allocator.ctx = (void*)&original_allocators[i];
        PyMem_SetAllocator(static_cast<PyMemAllocatorDomain>(i), &echion_allocator);
    }
}

// ----------------------------------------------------------------------------
void teardown_memory()
{
    // Restore the original allocators
    for (int i = 0; i < ALLOC_DOMAIN_COUNT; i++)
        PyMem_SetAllocator(static_cast<PyMemAllocatorDomain>(i), &original_allocators[i]);

    stack_stats.flush();

    stack_stats.clear();
    stack_table.clear();
    memory_table.clear();
}


// ============================================================================
// SOURCE FILES
// ============================================================================

// ============================================================================
// Source: coremodule.cc
// ============================================================================
// This file is part of "echion" which is released under MIT.
//
// Copyright (c) 2023 Gabriele N. Tornetta <phoenix1987@gmail.com>.

#define PY_SSIZE_T_CLEAN
#if PY_VERSION_HEX >= 0x030c0000
// https://github.com/python/cpython/issues/108216#issuecomment-1696565797
#undef _PyGC_FINALIZED
#endif


#if defined PL_DARWIN
#include <pthread.h>
#endif


// ----------------------------------------------------------------------------
void do_where(std::ostream& stream)
{
    WhereRenderer::get().set_output(stream);
    WhereRenderer::get().render_message("\rðŸ´ Echion reporting for duty");
    WhereRenderer::get().render_message("");

    for_each_interp([](InterpreterInfo& interp) -> void {
        for_each_thread(interp, [](PyThreadState* tstate, ThreadInfo& thread) -> void {
            thread.unwind(tstate);
            WhereRenderer::get().render_thread_begin(tstate, thread.name, /*cpu_time*/ 0,
                                                     tstate->thread_id, thread.native_id);

            if (native)
            {
                interleave_stacks();
                interleaved_stack.render_where();
            }
            else
                python_stack.render_where();
            WhereRenderer::get().render_message("");
        });
    });
}

// ----------------------------------------------------------------------------
void where_listener()
{
    for (;;)
    {
        std::unique_lock<std::mutex> lock(where_lock);
        where_cv.wait(lock);

        if (!running)
            break;

        do_where(std::cerr);
    }
}

// ----------------------------------------------------------------------------
void setup_where()
{
    where_thread = new std::thread(where_listener);
}

void teardown_where()
{
    if (where_thread != nullptr)
    {
        {
            std::lock_guard<std::mutex> lock(where_lock);

            where_cv.notify_one();
        }

        where_thread->join();

        where_thread = nullptr;
    }
}

// ----------------------------------------------------------------------------
void _start()
{
    init_frame_cache(CACHE_MAX_ENTRIES * (1 + native));

    try
    {
        Renderer::get().open();
    }
    catch (std::exception& e)
    {
        return;
    }

    install_signals();

#if defined PL_DARWIN
    // Get the wall time clock resource.
    host_get_clock_service(mach_host_self(), CALENDAR_CLOCK, &cclock);
#endif

    if (where)
    {
        std::ofstream pipe(pipe_name, std::ios::out);

        if (pipe)
            do_where(pipe);

        else
            std::cerr << "Failed to open pipe " << pipe_name << std::endl;

        running = 0;

        return;
    }

    setup_where();

    Renderer::get().header();

    if (memory)
    {
        Renderer::get().metadata("mode", "memory");
    }
    else
    {
        Renderer::get().metadata("mode", (cpu ? "cpu" : "wall"));
    }
    Renderer::get().metadata("interval", std::to_string(interval));
    Renderer::get().metadata("sampler", "echion");

    // DEV: Workaround for the austin-python library: we send an empty sample
    // to set the PID. We also map the key value 0 to the empty string, to
    // support task name frames.
    Renderer::get().render_stack_begin(pid, 0, "MainThread");
    Renderer::get().string(0, "");
    Renderer::get().string(1, "<invalid>");
    Renderer::get().string(2, "<unknown>");
    Renderer::get().render_stack_end(MetricType::Time, 0);

    if (memory)
        setup_memory();
}

// ----------------------------------------------------------------------------
void _stop()
{
    if (memory)
        teardown_memory();

    // Clean up the thread info map. When not running async, we need to guard
    // the map lock because we are not in control of the sampling thread.
    {
        const std::lock_guard<std::mutex> guard(thread_info_map_lock);

        thread_info_map.clear();
        string_table.clear();
    }

    teardown_where();

#if defined PL_DARWIN
    mach_port_deallocate(mach_task_self(), cclock);
#endif

    restore_signals();

    Renderer::get().close();

    reset_frame_cache();
}

// ----------------------------------------------------------------------------
void _sampler()
{
    // This function can run without the GIL on the basis that these assumptions
    // hold:
    // 1. The interpreter state object lives as long as the process itself.

    last_time = gettime();

    while (running)
    {
        microsecond_t now = gettime();
        microsecond_t end_time = now + interval;

        if (memory)
        {
            if (rss_tracker.check())
                stack_stats.flush();
        }
        else
        {
            microsecond_t wall_time = now - last_time;

            for_each_interp([=](InterpreterInfo& interp) -> void {
                for_each_thread(interp, [=](PyThreadState* tstate, ThreadInfo& thread) {
                    try {
                        thread.sample(interp.id, tstate, wall_time);
                    } catch (ThreadInfo::CpuTimeError& e) {
                        // Silently skip sampling this thread
                    }
                });
            });
        }

        std::this_thread::sleep_for(std::chrono::microseconds(end_time - now));
        last_time = now;
    }
}

void sampler()
{
    _start();
    _sampler();
    _stop();
}

// ----------------------------------------------------------------------------
void _init()
{
    pid = getpid();
}

// ----------------------------------------------------------------------------
PyObject* start_async(PyObject* Py_UNUSED(m), PyObject* Py_UNUSED(args))
{
    if (!running)
    {
        // TODO: Since we have a global state, we should not allow multiple ways
        // of starting the sampler.
        if (sampler_thread == nullptr)
        {
            running = 1;
            sampler_thread = new std::thread(sampler);
        }
    }

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* start(PyObject* Py_UNUSED(m), PyObject* Py_UNUSED(args))
{
    if (!running)
    {
        // TODO: Since we have a global state, we should not allow multiple ways
        // of starting the sampler.
        running = 1;

        // Run the sampler without the GIL
        Py_BEGIN_ALLOW_THREADS;
        sampler();
        Py_END_ALLOW_THREADS;
    }

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* stop(PyObject* Py_UNUSED(m), PyObject* Py_UNUSED(args))
{
    running = 0;

    // Stop the sampling thread
    if (sampler_thread != nullptr)
    {
        sampler_thread->join();
        sampler_thread = nullptr;
    }

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* track_thread(PyObject* Py_UNUSED(m), PyObject* args)
{
    uintptr_t thread_id;  // map key
    const char* thread_name;
    pid_t native_id;

    if (!PyArg_ParseTuple(args, "lsi", &thread_id, &thread_name, &native_id))
        return NULL;

    {
        const std::lock_guard<std::mutex> guard(thread_info_map_lock);

        auto entry = thread_info_map.find(thread_id);
        if (entry != thread_info_map.end())
            // Thread is already tracked so we update its info
            entry->second = std::make_unique<ThreadInfo>(thread_id, native_id, thread_name);
        else
            thread_info_map.emplace(
                thread_id, std::make_unique<ThreadInfo>(thread_id, native_id, thread_name));
    }

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* untrack_thread(PyObject* Py_UNUSED(m), PyObject* args)
{
    unsigned long thread_id;
    if (!PyArg_ParseTuple(args, "l", &thread_id))
        return NULL;

    {
        const std::lock_guard<std::mutex> guard(thread_info_map_lock);

        thread_info_map.erase(thread_id);
    }

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* init(PyObject* Py_UNUSED(m), PyObject* Py_UNUSED(args))
{
    _init();

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* track_asyncio_loop(PyObject* Py_UNUSED(m), PyObject* args)
{
    uintptr_t thread_id;  // map key
    PyObject* loop;

    if (!PyArg_ParseTuple(args, "lO", &thread_id, &loop))
        return NULL;

    {
        std::lock_guard<std::mutex> guard(thread_info_map_lock);

        if (thread_info_map.find(thread_id) != thread_info_map.end())
        {
            thread_info_map.find(thread_id)->second->asyncio_loop =
                (loop != Py_None) ? (uintptr_t)loop : 0;
        }
    }

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* init_asyncio(PyObject* Py_UNUSED(m), PyObject* args)
{
    if (!PyArg_ParseTuple(args, "OOO", &asyncio_current_tasks, &asyncio_scheduled_tasks,
                          &asyncio_eager_tasks))
        return NULL;

    if (asyncio_eager_tasks == Py_None)
        asyncio_eager_tasks = NULL;

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* track_greenlet(PyObject* Py_UNUSED(m), PyObject* args)
{
    uintptr_t greenlet_id;  // map key
    PyObject* name;
    PyObject* frame;

    if (!PyArg_ParseTuple(args, "lOO", &greenlet_id, &name, &frame))
        return NULL;

    StringTable::Key greenlet_name;

    try
    {
        greenlet_name = string_table.key(name);
    }
    catch (StringTable::Error&)
    {
        // We failed to get this task but we keep going
        PyErr_SetString(PyExc_RuntimeError, "Failed to get greenlet name from the string table");
        return NULL;
    }
    {
        const std::lock_guard<std::mutex> guard(greenlet_info_map_lock);

        auto entry = greenlet_info_map.find(greenlet_id);
        if (entry != greenlet_info_map.end())
            // Greenlet is already tracked so we update its info. This should
            // never happen, as a greenlet should be tracked only once, so we
            // use this as a safety net.
            entry->second = std::make_unique<GreenletInfo>(greenlet_id, frame, greenlet_name);
        else
            greenlet_info_map.emplace(
                greenlet_id, std::make_unique<GreenletInfo>(greenlet_id, frame, greenlet_name));

        // Update the thread map
        auto native_id = PyThread_get_thread_native_id();
        greenlet_thread_map[native_id] = greenlet_id;
    }

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* untrack_greenlet(PyObject* Py_UNUSED(m), PyObject* args)
{
    uintptr_t greenlet_id;
    if (!PyArg_ParseTuple(args, "l", &greenlet_id))
        return NULL;

    {
        const std::lock_guard<std::mutex> guard(greenlet_info_map_lock);

        greenlet_info_map.erase(greenlet_id);
        greenlet_parent_map.erase(greenlet_id);
        greenlet_thread_map.erase(greenlet_id);
    }
    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* link_greenlets(PyObject* Py_UNUSED(m), PyObject* args)
{
    uintptr_t parent, child;

    if (!PyArg_ParseTuple(args, "ll", &child, &parent))
        return NULL;

    {
        std::lock_guard<std::mutex> guard(greenlet_info_map_lock);

        greenlet_parent_map[child] = parent;
    }

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* update_greenlet_frame(PyObject* Py_UNUSED(m), PyObject* args)
{
    uintptr_t greenlet_id;
    PyObject* frame;

    if (!PyArg_ParseTuple(args, "lO", &greenlet_id, &frame))
        return NULL;

    {
        std::lock_guard<std::mutex> guard(greenlet_info_map_lock);

        auto entry = greenlet_info_map.find(greenlet_id);
        if (entry != greenlet_info_map.end())
        {
            // Update the frame of the greenlet
            entry->second->frame = frame;
        }
    }

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyObject* link_tasks(PyObject* Py_UNUSED(m), PyObject* args)
{
    PyObject *parent, *child;

    if (!PyArg_ParseTuple(args, "OO", &parent, &child))
        return NULL;

    {
        std::lock_guard<std::mutex> guard(task_link_map_lock);

        task_link_map[child] = parent;
    }

    Py_RETURN_NONE;
}

// ----------------------------------------------------------------------------
PyMethodDef echion_core_methods[] = {
    {"start", start, METH_NOARGS, "Start the stack sampler"},
    {"start_async", start_async, METH_NOARGS, "Start the stack sampler asynchronously"},
    {"stop", stop, METH_NOARGS, "Stop the stack sampler"},
    {"track_thread", track_thread, METH_VARARGS, "Map the name of a thread with its identifier"},
    {"untrack_thread", untrack_thread, METH_VARARGS, "Untrack a terminated thread"},
    {"init", init, METH_NOARGS, "Initialize the stack sampler (usually after a fork)"},
    // Task support
    {"track_asyncio_loop", track_asyncio_loop, METH_VARARGS,
     "Map the name of a task with its identifier"},
    {"init_asyncio", init_asyncio, METH_VARARGS, "Initialise asyncio tracking"},
    {"link_tasks", link_tasks, METH_VARARGS, "Link two tasks"},
    // Greenlet support
    {"track_greenlet", track_greenlet, METH_VARARGS, "Map a greenlet with its identifier"},
    {"untrack_greenlet", untrack_greenlet, METH_VARARGS, "Untrack a terminated greenlet"},
    {"link_greenlets", link_greenlets, METH_VARARGS, "Link two greenlets"},
    {"update_greenlet_frame", update_greenlet_frame, METH_VARARGS,
     "Update the frame of a greenlet"},
    // Configuration interface
    {"set_interval", set_interval, METH_VARARGS, "Set the sampling interval"},
    {"set_cpu", set_cpu, METH_VARARGS, "Set whether to use CPU time instead of wall time"},
    {"set_memory", set_memory, METH_VARARGS, "Set whether to sample memory usage"},
    {"set_native", set_native, METH_VARARGS, "Set whether to sample the native stacks"},
    {"set_where", set_where, METH_VARARGS, "Set whether to use where mode"},
    {"set_pipe_name", set_pipe_name, METH_VARARGS, "Set the pipe name"},
    {"set_max_frames", set_max_frames, METH_VARARGS, "Set the max number of frames to unwind"},
    // Sentinel
    {NULL, NULL, 0, NULL}
};

// ----------------------------------------------------------------------------
struct PyModuleDef coremodule = {
    PyModuleDef_HEAD_INIT,
    "core", /* name of module */
    NULL,   /* module documentation, may be NULL */
    -1,     /* size of per-interpreter state of the module,
               or -1 if the module keeps state in global variables. */
    echion_core_methods,
};

// ----------------------------------------------------------------------------
PyMODINIT_FUNC PyInit_core(void)
{
    PyObject* m;

    m = PyModule_Create(&coremodule);
    if (m == NULL)
        return NULL;

    // We make the assumption that this module is loaded by the main thread.
    // TODO: These need to be reset after a fork.
    _init();

    return m;
}


// ============================================================================
// Source: frame.cc
// ============================================================================


// ----------------------------------------------------------------------------
#if PY_VERSION_HEX >= 0x030b0000
int _read_varint(unsigned char* table, ssize_t size, ssize_t* i)
{
    ssize_t guard = size - 1;
    if (*i >= guard)
        return 0;

    int val = table[++*i] & 63;
    int shift = 0;
    while (table[*i] & 64 && *i < guard)
    {
        shift += 6;
        val |= (table[++*i] & 63) << shift;
    }
    return val;
}

// ----------------------------------------------------------------------------
int _read_signed_varint(unsigned char* table, ssize_t size, ssize_t* i)
{
    int val = _read_varint(table, size, i);
    return (val & 1) ? -(val >> 1) : (val >> 1);
}
#endif

// ----------------------------------------------------------------------------
void init_frame_cache(size_t capacity)
{
    frame_cache = new LRUCache<uintptr_t, Frame>(capacity);
}

// ----------------------------------------------------------------------------
void reset_frame_cache()
{
    delete frame_cache;
    frame_cache = nullptr;
}

// ------------------------------------------------------------------------
Frame::Frame(PyObject* frame)
{
#if PY_VERSION_HEX >= 0x030b0000

#if PY_VERSION_HEX >= 0x030d0000
    _PyInterpreterFrame* iframe = reinterpret_cast<_PyInterpreterFrame*>(frame);
    const int lasti = _PyInterpreterFrame_LASTI(iframe);
    PyCodeObject* code = reinterpret_cast<PyCodeObject*>(iframe->f_executable);
#else
    const _PyInterpreterFrame* iframe = reinterpret_cast<_PyInterpreterFrame*>(frame);
    const int lasti = _PyInterpreterFrame_LASTI(iframe);
    PyCodeObject* code = iframe->f_code;
#endif  // PY_VERSION_HEX >= 0x030d0000
    PyCode_Addr2Location(code, lasti << 1, &location.line, &location.column, &location.line_end,
                         &location.column_end);
    location.column++;
    location.column_end++;
    name = string_table.key_unsafe(code->co_qualname);
#if PY_VERSION_HEX >= 0x030c0000
    is_entry = (iframe->owner == FRAME_OWNED_BY_CSTACK);  // Shim frame
#else
    is_entry = iframe->is_entry;
#endif

#else
    PyFrameObject* py_frame = reinterpret_cast<PyFrameObject*>(frame);
    PyCodeObject* code = py_frame->f_code;

    location.line = PyFrame_GetLineNumber(py_frame);
    name = string_table.key_unsafe(code->co_name);
#endif
    filename = string_table.key_unsafe(code->co_filename);
}

// ------------------------------------------------------------------------
Frame::Frame(PyCodeObject* code, int lasti)
{
    try
    {
        filename = string_table.key(code->co_filename);
#if PY_VERSION_HEX >= 0x030b0000
        name = string_table.key(code->co_qualname);
#else
        name = string_table.key(code->co_name);
#endif
    }
    catch (StringTable::Error&)
    {
        throw Error();
    }

    infer_location(code, lasti);
}

// ------------------------------------------------------------------------
#ifndef UNWIND_NATIVE_DISABLE
Frame::Frame(unw_cursor_t& cursor, unw_word_t pc)
{
    try
    {
        filename = string_table.key(pc);
        name = string_table.key(cursor);
    }
    catch (StringTable::Error&)
    {
        throw Error();
    }
}
#endif  // UNWIND_NATIVE_DISABLE

// ----------------------------------------------------------------------------
void Frame::infer_location(PyCodeObject* code_obj, int lasti)
{
    unsigned int lineno = code_obj->co_firstlineno;
    Py_ssize_t len = 0;

#if PY_VERSION_HEX >= 0x030b0000
    auto table = pybytes_to_bytes_and_size(code_obj->co_linetable, &len);
    if (table == nullptr)
        throw LocationError();

    auto table_data = table.get();

    for (Py_ssize_t i = 0, bc = 0; i < len; i++)
    {
        bc += (table[i] & 7) + 1;
        int code = (table[i] >> 3) & 15;
        unsigned char next_byte = 0;
        switch (code)
        {
            case 15:
                break;

            case 14:  // Long form
                lineno += _read_signed_varint(table_data, len, &i);

                this->location.line = lineno;
                this->location.line_end = lineno + _read_varint(table_data, len, &i);
                this->location.column = _read_varint(table_data, len, &i);
                this->location.column_end = _read_varint(table_data, len, &i);

                break;

            case 13:  // No column data
                lineno += _read_signed_varint(table_data, len, &i);

                this->location.line = lineno;
                this->location.line_end = lineno;
                this->location.column = this->location.column_end = 0;

                break;

            case 12:  // New lineno
            case 11:
            case 10:
                if (i >= len - 2)
                    throw LocationError();

                lineno += code - 10;

                this->location.line = lineno;
                this->location.line_end = lineno;
                this->location.column = 1 + table[++i];
                this->location.column_end = 1 + table[++i];

                break;

            default:
                if (i >= len - 1)
                    throw LocationError();

                next_byte = table[++i];

                this->location.line = lineno;
                this->location.line_end = lineno;
                this->location.column = 1 + (code << 3) + ((next_byte >> 4) & 7);
                this->location.column_end = this->location.column + (next_byte & 15);
        }

        if (bc > lasti)
            break;
    }

#elif PY_VERSION_HEX >= 0x030a0000
    auto table = pybytes_to_bytes_and_size(code_obj->co_linetable, &len);
    if (table == nullptr)
        throw LocationError();

    lasti <<= 1;
    for (int i = 0, bc = 0; i < len; i++)
    {
        int sdelta = table[i++];
        if (sdelta == 0xff)
            break;

        bc += sdelta;

        int ldelta = table[i];
        if (ldelta == 0x80)
            ldelta = 0;
        else if (ldelta > 0x80)
            lineno -= 0x100;

        lineno += ldelta;
        if (bc > lasti)
            break;
    }

#else
    auto table = pybytes_to_bytes_and_size(code_obj->co_lnotab, &len);
    if (table == nullptr)
        throw LocationError();

    for (int i = 0, bc = 0; i < len; i++)
    {
        bc += table[i++];
        if (bc > lasti)
            break;

        if (table[i] >= 0x80)
            lineno -= 0x100;

        lineno += table[i];
    }

#endif

    this->location.line = lineno;
    this->location.line_end = lineno;
    this->location.column = 0;
    this->location.column_end = 0;
}

// ------------------------------------------------------------------------
Frame::Key Frame::key(PyCodeObject* code, int lasti)
{
    return ((static_cast<uintptr_t>(((reinterpret_cast<uintptr_t>(code)))) << 16) | lasti);
}

// ----------------------------------------------------------------------------
Frame::Key Frame::key(PyObject* frame)
{
#if PY_VERSION_HEX >= 0x030d0000
    _PyInterpreterFrame* iframe = reinterpret_cast<_PyInterpreterFrame*>(frame);
    const int lasti = _PyInterpreterFrame_LASTI(iframe);
    PyCodeObject* code = reinterpret_cast<PyCodeObject*>(iframe->f_executable);
#elif PY_VERSION_HEX >= 0x030b0000
    const _PyInterpreterFrame* iframe = reinterpret_cast<_PyInterpreterFrame*>(frame);
    const int lasti = _PyInterpreterFrame_LASTI(iframe);
    PyCodeObject* code = iframe->f_code;
#else
    const PyFrameObject* py_frame = reinterpret_cast<PyFrameObject*>(frame);
    const int lasti = py_frame->f_lasti;
    PyCodeObject* code = py_frame->f_code;
#endif
    return key(code, lasti);
}

// ------------------------------------------------------------------------
#if PY_VERSION_HEX >= 0x030b0000
Frame& Frame::read(_PyInterpreterFrame* frame_addr, _PyInterpreterFrame** prev_addr)
#else
Frame& Frame::read(PyObject* frame_addr, PyObject** prev_addr)
#endif
{
#if PY_VERSION_HEX >= 0x030b0000
    _PyInterpreterFrame iframe;
#if PY_VERSION_HEX >= 0x030d0000
    // From Python versions 3.13, f_executable can have objects other than
    // code objects for an internal frame. We need to skip some frames if
    // its f_executable is not code as suggested here:
    // https://github.com/python/cpython/issues/100987#issuecomment-1485556487
    PyObject f_executable;

    for (; frame_addr; frame_addr = frame_addr->previous)
    {
        auto resolved_addr =
            stack_chunk ? reinterpret_cast<_PyInterpreterFrame*>(stack_chunk->resolve(frame_addr))
                        : frame_addr;
        if (resolved_addr != frame_addr)
        {
            frame_addr = resolved_addr;
        }
        else
        {
            if (copy_type(frame_addr, iframe))
            {
                throw Frame::Error();
            }
            frame_addr = &iframe;
        }
        if (copy_type(frame_addr->f_executable, f_executable))
        {
            throw Frame::Error();
        }
        if (f_executable.ob_type == &PyCode_Type)
        {
            break;
        }
    }

    if (frame_addr == NULL)
    {
        throw Frame::Error();
    }
#else   // PY_VERSION_HEX < 0x030d0000
    // Code Specific to Python < 3.13 and >= 3.11
    auto resolved_addr =
        stack_chunk ? reinterpret_cast<_PyInterpreterFrame*>(stack_chunk->resolve(frame_addr))
                    : frame_addr;
    if (resolved_addr != frame_addr)
    {
        frame_addr = resolved_addr;
    }
    else
    {
        if (copy_type(frame_addr, iframe))
        {
            throw Frame::Error();
        }
        frame_addr = &iframe;
    }
#endif  // PY_VERSION_HEX >= 0x030d0000

    // We cannot use _PyInterpreterFrame_LASTI because _PyCode_CODE reads
    // from the code object.
#if PY_VERSION_HEX >= 0x030d0000
    const int lasti =
        (static_cast<int>((frame_addr->instr_ptr - 1 -
                           reinterpret_cast<_Py_CODEUNIT*>(
                               (reinterpret_cast<PyCodeObject*>(frame_addr->f_executable)))))) -
        offsetof(PyCodeObject, co_code_adaptive) / sizeof(_Py_CODEUNIT);
    auto& frame = Frame::get(reinterpret_cast<PyCodeObject*>(frame_addr->f_executable), lasti);
#else
    const int lasti = (static_cast<int>((frame_addr->prev_instr -
                                         reinterpret_cast<_Py_CODEUNIT*>((frame_addr->f_code))))) -
                      offsetof(PyCodeObject, co_code_adaptive) / sizeof(_Py_CODEUNIT);
    auto& frame = Frame::get(frame_addr->f_code, lasti);
#endif  // PY_VERSION_HEX >= 0x030d0000
    if (&frame != &INVALID_FRAME)
    {
#if PY_VERSION_HEX >= 0x030c0000
        frame.is_entry = (frame_addr->owner == FRAME_OWNED_BY_CSTACK);  // Shim frame
#else   // PY_VERSION_HEX < 0x030c0000
        frame.is_entry = frame_addr->is_entry;
#endif  // PY_VERSION_HEX >= 0x030c0000
    }

    *prev_addr = &frame == &INVALID_FRAME ? NULL : frame_addr->previous;

#else   // PY_VERSION_HEX < 0x030b0000
    // Unwind the stack from leaf to root and store it in a stack. This way we
    // can print it from root to leaf.
    PyFrameObject py_frame;

    if (copy_type(frame_addr, py_frame))
        throw Error();

    auto& frame = Frame::get(py_frame.f_code, py_frame.f_lasti);

    *prev_addr = (&frame == &INVALID_FRAME) ? NULL : reinterpret_cast<PyObject*>(py_frame.f_back);
#endif  // PY_VERSION_HEX >= 0x030b0000

    return frame;
}

// ----------------------------------------------------------------------------
Frame& Frame::get(PyCodeObject* code_addr, int lasti)
{
    auto frame_key = Frame::key(code_addr, lasti);

    try
    {
        return frame_cache->lookup(frame_key);
    }
    catch (LRUCache<uintptr_t, Frame>::LookupError&)
    {
        try
        {
            PyCodeObject code;
            if (copy_type(code_addr, code))
                return INVALID_FRAME;

            auto new_frame = std::make_unique<Frame>(&code, lasti);
            new_frame->cache_key = frame_key;
            auto& f = *new_frame;
            Renderer::get().frame(frame_key, new_frame->filename, new_frame->name,
                                  new_frame->location.line, new_frame->location.line_end,
                                  new_frame->location.column, new_frame->location.column_end);
            frame_cache->store(frame_key, std::move(new_frame));
            return f;
        }
        catch (Frame::Error&)
        {
            return INVALID_FRAME;
        }
    }
}

// ----------------------------------------------------------------------------
Frame& Frame::get(PyObject* frame)
{
    auto frame_key = Frame::key(frame);

    try
    {
        return frame_cache->lookup(frame_key);
    }
    catch (LRUCache<uintptr_t, Frame>::LookupError&)
    {
        auto new_frame = std::make_unique<Frame>(frame);
        new_frame->cache_key = frame_key;
        auto& f = *new_frame;
        Renderer::get().frame(frame_key, new_frame->filename, new_frame->name,
                              new_frame->location.line, new_frame->location.line_end,
                              new_frame->location.column, new_frame->location.column_end);
        frame_cache->store(frame_key, std::move(new_frame));
        return f;
    }
}

// ----------------------------------------------------------------------------
#ifndef UNWIND_NATIVE_DISABLE
Frame& Frame::get(unw_cursor_t& cursor)
{
    unw_word_t pc;
    unw_get_reg(&cursor, UNW_REG_IP, &pc);
    if (pc == 0)
        throw Error();

    uintptr_t frame_key = (uintptr_t)pc;
    try
    {
        return frame_cache->lookup(frame_key);
    }
    catch (LRUCache<uintptr_t, Frame>::LookupError&)
    {
        try
        {
            auto frame = std::make_unique<Frame>(cursor, pc);
            frame->cache_key = frame_key;
            auto& f = *frame;
            Renderer::get().frame(frame_key, frame->filename, frame->name, frame->location.line,
                                  frame->location.line_end, frame->location.column,
                                  frame->location.column_end);
            frame_cache->store(frame_key, std::move(frame));
            return f;
        }
        catch (Frame::Error&)
        {
            return UNKNOWN_FRAME;
        }
    }
}
#endif  // UNWIND_NATIVE_DISABLE

// ----------------------------------------------------------------------------
Frame& Frame::get(StringTable::Key name)
{
    uintptr_t frame_key = static_cast<uintptr_t>(name);
    try
    {
        return frame_cache->lookup(frame_key);
    }
    catch (LRUCache<uintptr_t, Frame>::LookupError&)
    {
        auto frame = std::make_unique<Frame>(name);
        frame->cache_key = frame_key;
        auto& f = *frame;
        Renderer::get().frame(frame_key, frame->filename, frame->name, frame->location.line,
                              frame->location.line_end, frame->location.column,
                              frame->location.column_end);
        frame_cache->store(frame_key, std::move(frame));
        return f;
    }
}


// ============================================================================
// Source: render.cc
// ============================================================================

// ------------------------------------------------------------------------
void WhereRenderer::render_frame(Frame& frame)
{
    auto name_str = string_table.lookup(frame.name);
    auto filename_str = string_table.lookup(frame.filename);
    auto line = frame.location.line;

    if (filename_str.rfind("native@", 0) == 0)
    {
        WhereRenderer::get().render_message(
            "\033[38;5;248;1m" + name_str + "\033[0m \033[38;5;246m(" + filename_str +
            "\033[0m:\033[38;5;246m" + std::to_string(line) + ")\033[0m");
    }
    else
    {
        WhereRenderer::get().render_message("\033[33;1m" + name_str + "\033[0m (\033[36m" +
                                            filename_str + "\033[0m:\033[32m" +
                                            std::to_string(line) + "\033[0m)");
    }
}

// ------------------------------------------------------------------------
void MojoRenderer::render_frame(Frame& frame)
{
    frame_ref(frame.cache_key);
}


